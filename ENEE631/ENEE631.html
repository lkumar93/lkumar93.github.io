<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Digital Image and Video Processing</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/agency.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/print.css" type="text/css" media="print">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <!--<a class="navbar-brand page-scroll" href="#page-top">Start Bootstrap</a>-->
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>                    
                    <li>
                        <a class="page-scroll" href="#about">Updates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#portfolio">Experiments</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#project_progress">Project</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#team">About Author</a>
                    </li>
<!--                    <li>
                        <a class="page-scroll" href="#contact">Contact</a>
                    </li>-->
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="intro-text">
                <div class="intro-lead-in">My Web Journal On</div>
                <div class="intro-heading" style="margin-top:50px;margin-bottom:75px">Digital Image and Video Processing
                </div>
                <div class="intro-lead-in" style="margin-bottom:70px">- Lakshman Kumar</div>
                
                 <a href="#about" class="page-scroll btn btn-xl" id="explore_button">Explore</a>
               </div>
               
            </div>
        </div>
    </header>
    
    

   <!-- About Section -->
    <section id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEKLY UPDATES</h2>
                    <h3 class="section-subheading text-muted"></h3>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <ul class="timeline">
                        <li>
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> I </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 1</h4>
                                    <h4 class="subheading">02/08/2017</h4>
                                </div>
                                <div class="timeline-body">
                                   <div align="justify">
                                    <p class="text-muted">The effects of various levels of sampling and quantization on an image were observed. Mean squared error was computed to measure quality of the processed image with respect to original image. </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <li class="timeline-inverted">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> II </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 2</h4>
                                    <h4 class="subheading">02/15/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted">Images were subjected to point operations in order to enhance it. Also, the histogram of images were computed, analyzed and equalized in-order to improve the contrast of the image.</p>
									</div>
                                </div>
                            </div>
                        </li>
                                                <li>
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> III </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 3</h4>
                                    <h4 class="subheading">02/22/2017</h4>
                                </div>
                                <div class="timeline-body">
                                   <div align="justify">
                                    <p class="text-muted">Various spatial filters were applied to the images and the results were analyzed. The images were sharpened in order to enhance the edges. </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        
                          <li class="timeline-inverted">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> IV </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 4</h4>
                                    <h4 class="subheading">03/01/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted">A modified version of Gaussian filter called Bilateral filter was implemented and the results were compared with Gaussian Filters. Morphological filters like erosion and dilation were applied to the images and tested.</p>
									</div>
                                </div>
                            </div>
                        </li>
                        
                         <li>
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> V </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 5</h4>
                                    <h4 class="subheading">03/08/2017</h4>
                                </div>
                                <div class="timeline-body">
                                   <div align="justify">
                                    <p class="text-muted">Canny edge detection was implemented and the results were compared with Sobel edge detection. Images were analyzed and filtered based on the noise present in the image. </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        
                        <li class="timeline-inverted">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> VI </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 6</h4>
                                    <h4 class="subheading">03/15/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted">Deconvolution was performed using inverse, pseudo-inverse and wiener filters. The filters were tested on images with gaussian blur, motion blur and additive gaussian noise.</p>
									</div>
                                </div>
                            </div>
                        </li>
                        
                        <li class="timeline-image">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> VII </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 7</h4>
                                    <h4 class="subheading">03/29/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted"> Run length encoding and Huffman encoding were implemented on a given dataset and the resulting compression effects were observed and analyzed</p>
									</div>
                                </div>
                            </div>
                        </li>
                        
                         <li class="timeline-inverted">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> VIII </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 8</h4>
                                    <h4 class="subheading">04/05/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted"> Block Based Discrete Cosine Transforms were used to analyze images for use in compression. Blurred Images were partially restored using pseudo inverse filters.</p>
									</div>
                                </div>
                            </div>
                        </li>
                        
                       <li class="timeline-image">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> IX </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Week 9</h4>
                                    <h4 class="subheading">04/26/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted"> Adaptive Thresholding was implemented and the results were compared with Global Thresholding. Corner features in an image were extracted using Harris Corner Detection method. </p>
									</div>
                                </div>
                            </div>
                        </li>
                        
                        
                        <li>
                            <div class="timeline-inverted">
                                <div class="timeline-image">
                                <h4>Next Update
                                    <br> On
                                    <br>05/10/17</h4>
                            </div>
                            </div>

                        </li>
                 
                    </ul>
                </div>
            </div>
        </div>
    </section>
   
    <!-- Portfolio Grid Section -->
    <section id="portfolio" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Experiments</h2>
                    <h3 class="section-subheading text-muted">Here are some experiments done based on weekly lectures using OpenCV </h3>
                </div>
            </div>
            <div class="row">
                <div class="col-md-4 col-sm-6 portfolio-item">
                    <a href="#week1" class="page-scroll ">
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week1/mickey_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 1</h4>
                        <p class="text-muted">Sampling, Quantization and Mean Squared Error</p>
                    </div>
                </div>
                
               <div class="col-md-4 col-sm-6 portfolio-item">

                    <a href="#week2" class="page-scroll " >
                    
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week2/histogram_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 2</h4>
                        <p class="text-muted">Point Operations and Histogram Equalization</p>
                    </div>
                </div>
                            
                 <div class="col-md-4 col-sm-6 portfolio-item">

                    <a href="#week3" class="page-scroll " >
                    
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week3/balloons_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 3</h4>
                        <p class="text-muted">Spatial Filters and Sharpening</p>
                    </div>
                </div>
                </div>
                           
            <div class="row"> 
                 <div class="col-md-4 col-sm-6 portfolio-item">

                    <a href="#week4" class="page-scroll " >
                    
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week4/fingerprint_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 4</h4>
                        <p class="text-muted">Bilateral and Morphological Filters</p>
                    </div>
                </div>
                            
                 <div class="col-md-4 col-sm-6 portfolio-item">

                    <a href="#week5" class="page-scroll " >
                    
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week5/plane_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 5</h4>
                        <p class="text-muted">Canny Edge Detection and Noise Removal</p>
                    </div>
                </div>

                  
                <div class="col-md-4 col-sm-6 portfolio-item">

                    <a href="#week6" class="page-scroll " >
                    
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week6/horse_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 6</h4>
                        <p class="text-muted">Inverse, Pseudo-Inverse and Wiener Filters</p>
                    </div>
                </div>
                
                </div>
                  
                 <div class="row"> 
                 <div class="col-md-4 col-sm-6 portfolio-item">

                    <a href="#week7" class="page-scroll " >
                    
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week7/huffman_encoding_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 7</h4>
                        <p class="text-muted">Compression</p>
                    </div>
                </div>
                                           
                <div class="col-md-4 col-sm-6 portfolio-item">

                    <a href="#week8" class="page-scroll " >
                    
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week8/dct_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 8</h4>
                        <p class="text-muted">Discrete Cosine Transforms</p>
                    </div>
                </div>
                                           
                 <div class="col-md-4 col-sm-6 portfolio-item">

                    <a href="#week9" class="page-scroll " >
                    
                        <div class="portfolio-hover">
                        </div>
                        <img src="img/week9/thresholding_dp.jpg" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>Week 9</h4>
                        <p class="text-muted">Harris Corner Detection and Adaptive Thresholding</p>
                    </div>
                </div>
                                            
                </div>
                   
            </div>

    </section>

    <section id="week1" >
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 1</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week1/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Sampling</h2>
                            <div id="25_padding" style="margin-bottom:25px"></div>
                            <p>Sampling is the process by which the values of the image at all the points on the rectangular grid of the image plane are obtained. They can be done at various frequencies/resolutions. However when the sampling rate (resolution) is below the nyquist rate, the information can be lost. Below you can see the picture of mickey mouse at various resolutions ( 640 X 480, 320 X 240, 32 X 24 ). It can be observed that at the resolution of 32 X 24 the figure of mickey mouse is not clear and hence the information has been lost due to aliasing. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>	
                            <div style="margin-bottom:25px"></div>
								<h4>640 X 480 <div style="margin-bottom:25px"></div>
                            <img src="img/week1/sampling/original_image.jpg" alt=""></h4>
                                            
                            <div style="margin-bottom:50px"></div>
                            <h4>320 X 240
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week1/sampling/320_x_240_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div> 
                            <h4>32 X 24
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week1/sampling/32_x_24_image.jpg" alt=""></h4>
							<div style="margin-bottom:50px"></div>
                            <h3>Code
                            <pre><code class="language-c++">
#include < stdio.h >
#include < opencv2/opencv.hpp >


using namespace cv;

int main(int argc, char** argv )
{
    Mat image;
    image = imread( "../images/mickey.jpg", 1 );

    cv::Mat resized_image1 = cv::Mat(240, 320, CV_8UC3, cv::Scalar(0, 0, 0)) ;
    cv::Mat resized_image2 = cv::Mat(24, 32, CV_8UC3, cv::Scalar(0, 0, 0)) ;

    int rows = 600;
    int cols = 800;

    resize(image,resized_image1,resized_image1.size(),0,0);
    resize(image,resized_image2,resized_image2.size(),0,0);


    if ( !image.data )
    {
        printf("No image data \n");
        return -1;
    }

    namedWindow("Original Image", WINDOW_NORMAL);
    resizeWindow("Original Image",rows,cols);
    imwrite( "../results/sampling/original_image.jpg", image );
    imshow("Original Image", image);


    namedWindow("320X240 Image", WINDOW_NORMAL );
    resizeWindow("320X240 Image",rows,cols);
    imwrite( "../results/sampling/320_x_240_image.jpg", resized_image1);
    imshow("320X240 Image", resized_image1);

    namedWindow("32X24 Image", WINDOW_NORMAL );
    resizeWindow("32X24 Image",rows,cols);
    imwrite( "../results/sampling/32_x_24_image.jpg", resized_image2 );
    imshow("32X24 Image", resized_image2);

    waitKey(0);

    return 0;
}
</code></pre></h3>
								<br></br><br></br>
                            <h2>Quantization and Mean Squared Error</h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p>Quantization is the process by which the sampled values of the image are approximated based on the desired number of distinct values. As the desired number of distinct values decreases, the quality of the image also decreases. The quality of the images can be determined using the Average Mean Squared Error, which is the average of squared difference of pixel luminance between the original image and the image with reduced number of distinct values. Below you can see the picture of avengers at various quantizations per channel ( 8-bit, 4-bit, 2-bit, 1-bit ). It can be observed that the mean squared error increases as the image is more approximated, resulting in loss of quality. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Original 8-Bit Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week1/quantization/original_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>4-Bit Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week1/quantization/4_bit_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>2-Bit Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week1/quantization/2_bit_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>1-Bit Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week1/quantization/1_bit_image.jpg" alt=""> </h4>
							</div>

                           	<div style="margin-bottom:50px"></div>
                           	 <h3>Code
                            <pre><code class="language-c++">
#include < stdio.h >
#include < opencv2/opencv.hpp >
#include < math.h >

using namespace cv;


Mat quantize(const Mat& input_image,int number_of_bits)
{

    Mat quantized_image = input_image.clone();

    uchar masked_bit = 0xFF;

    masked_bit = masked_bit << (8 - number_of_bits);

    for(int j = 0; j < quantized_image.rows; j++)
        for(int i = 0; i < quantized_image.cols; i++)
        {
            Vec3b rgb_value = quantized_image.at<Vec3b>(j, i);
            rgb_value[0] = rgb_value[0] & masked_bit;
            rgb_value[1] = rgb_value[1] & masked_bit;
            rgb_value[2] = rgb_value[2] & masked_bit;
            quantized_image.at<Vec3b>(j, i) = rgb_value;
        }

    return quantized_image;

}

float mean_squared_error(const Mat& image_1, const Mat& image_2)
{

   int m = image_1.rows;
   int n = image_1.cols;

   float mse = 0.0;

    for(int j = 0; j < m ; j++)
        for(int i = 0; i < n; i++)
        {
            Vec3b rgb_value_1 = image_1.at<Vec3b>(j, i);
	    Vec3b rgb_value_2 = image_2.at<Vec3b>(j, i);

	    mse += abs(rgb_value_1[0]-rgb_value_2[0])^2 + abs(rgb_value_1[1]-rgb_value_2[1])^2 + abs(rgb_value_1[2]-rgb_value_2[2])^2 ;
        }

    return mse/(m*n*3);
}

int main(int argc, char** argv )
{
    Mat image, image_4_bit, image_2_bit, image_1_bit;
    image = imread( "../images/avengers.jpg", 1 );

    if ( !image.data )
    {
        printf("No image data \n");
        return -1;
    }

    image_4_bit = quantize(image,4);
    image_2_bit = quantize(image,2);
    image_1_bit = quantize(image,1);

    float mse_4_bit, mse_2_bit, mse_1_bit;

    mse_4_bit = mean_squared_error(image,image_4_bit);
    mse_2_bit = mean_squared_error(image,image_2_bit);
    mse_1_bit = mean_squared_error(image,image_1_bit);

    std::ostringstream str_4_bit, str_2_bit,str_1_bit;

    str_4_bit << "MSE of 4 Bit Image = " << mse_4_bit;
    str_2_bit << "MSE of 2 Bit Image = " << mse_2_bit;
    str_1_bit << "MSE of 1 Bit Image = " << mse_1_bit;

    namedWindow("Original Image", WINDOW_AUTOSIZE);
    imwrite( "../results/quantization/original_image.jpg", image );
    imshow("Original Image", image);

    namedWindow("4 bit Image", WINDOW_AUTOSIZE);

    putText(image_4_bit, str_4_bit.str(), cvPoint(30,30), 
    FONT_HERSHEY_COMPLEX_SMALL, 0.8, cvScalar(200,200,250), 1, CV_AA);

    imwrite( "../results/quantization/4_bit_image.jpg", image_4_bit);
    imshow("4 bit Image", image_4_bit);

    namedWindow("2 bit Image", WINDOW_AUTOSIZE);

    putText(image_2_bit, str_2_bit.str(), cvPoint(30,30), 
    FONT_HERSHEY_COMPLEX_SMALL, 0.8, cvScalar(200,200,250), 1, CV_AA);


    imwrite( "../results/quantization/2_bit_image.jpg", image_2_bit);
    imshow("2 bit Image", image_2_bit);

    namedWindow("1 bit Image", WINDOW_AUTOSIZE);

    putText(image_1_bit, str_1_bit.str(), cvPoint(30,30), 
    FONT_HERSHEY_COMPLEX_SMALL, 0.8, cvScalar(200,200,250), 1, CV_AA);


    imwrite( "../results/quantization/1_bit_image.jpg", image_1_bit);
    imshow("1 bit Image", image_1_bit);

    waitKey(0);

    return 0;
}
</code></pre></h3>
</p>
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
        
        
    </section>
    
        <section id="week2" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 2</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week2/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Point Operations</h2>
                            <div style="margin-bottom:25px"></div>
                            <p>Point Operations are memoryless operations that functionally maps the intensity levels of an image to another level. This can be used to enhance the appearance of the image and feature extraction. Some of the point operations done on the image of Einstein are shown below. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>RGB Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week2/point_transformations/rgb_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Grayscale Image
                            <p>RGB images can be converted to grayscale by taking a proportion of the value in each color channel.
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week2/point_transformations/grayscale_image.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Inverse Image
                            <p> Inverse operation gives the negative of the image.
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week2/point_transformations/inverse_image.jpg" alt=""></p></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Log Image
                            <p>Log operations ,on the image intensities, non-linearly transforms the image .
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week2/point_transformations/log_image.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Gamma Corrected Image
                            <p>Gamma correction can be done to compensate for the non-linearities in brightness of various displays. 
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week2/point_transformations/gamma_corrected_image.jpg" alt=""></h5></h4>
							<div style="margin-bottom:50px"></div>
                            <h3>Code
                            <div style="margin-bottom:5px"></div>
                            <pre><code class="language-c++">
#include < stdio.h >
#include < opencv2/opencv.hpp >
#include < math.h >

#define R_WEIGHT 0.2989
#define G_WEIGHT 0.5870
#define B_WEIGHT 0.1140
#define TRANSFORMATION_CONSTANT 25
#define GAMMA 0.95

using namespace cv;


Mat convert_to_grayscale(const Mat& input_image)
{

    Mat rgb_image = input_image.clone();
    Mat grayscale_image = cv::Mat(rgb_image.rows, rgb_image.cols, CV_8UC1, cv::Scalar(0, 0, 0));

    for(int j = 0; j < grayscale_image.rows; j++)
        for(int i = 0; i < grayscale_image.cols; i++)
        {
            Vec3b rgb_value = rgb_image.at<Vec3b>(j, i);
	    grayscale_image.at< uchar >(j,i) = R_WEIGHT*rgb_value[0] + G_WEIGHT*rgb_value[1] + B_WEIGHT*rgb_value[2] ;
        }

    return grayscale_image;

}


Mat log_transformation(const Mat& input_image)
{

   Mat log_image = input_image.clone();

   for(int j = 0; j < log_image.rows ; j++)
        for(int i = 0; i < log_image.cols; i++)
        {
	    log_image.at< uchar >(j,i) = TRANSFORMATION_CONSTANT*log(log_image.at< uchar >(j,i)+1);
        }

    return log_image;
}

Mat inverse_transformation(const Mat& input_image)
{

   Mat inverse_image = input_image.clone();

   for(int j = 0; j < inverse_image.rows ; j++)
        for(int i = 0; i < inverse_image.cols; i++)
        {
	    inverse_image.at< uchar >(j,i) = 255 - inverse_image.at< uchar >(j,i);
        }

    return inverse_image;
}

Mat gamma_correction(const Mat& input_image)
{

   Mat gamma_corrected_image = input_image.clone();

   for(int j = 0; j < gamma_corrected_image.rows ; j++)
        for(int i = 0; i < gamma_corrected_image.cols; i++)
        {
	    gamma_corrected_image.at< uchar >(j,i) = pow( gamma_corrected_image.at< uchar >(j,i) , GAMMA );
        }

    return gamma_corrected_image;
}

int main(int argc, char** argv )
{
    Mat image, grayscale_image, log_image, inverse_image, gamma_corrected_image;

    image = imread( "../images/einstein.jpg", 1 );

    if ( !image.data )
    {
        printf("No image data \n");
        return -1;
    }

    grayscale_image = convert_to_grayscale(image);
    inverse_image = inverse_transformation(grayscale_image);
    log_image = log_transformation(grayscale_image);
    gamma_corrected_image = gamma_correction(grayscale_image);

    namedWindow("RGB Image", WINDOW_AUTOSIZE);
    imwrite( "../results/point_transformations/rgb_image.jpg", image );
    imshow("RGB Image", image);

    namedWindow("Grayscale Image", WINDOW_AUTOSIZE);
    imwrite( "../results/point_transformations/grayscale_image.jpg", grayscale_image );
    imshow("Grayscale Image", grayscale_image);

    namedWindow("Inverse Image", WINDOW_AUTOSIZE);
    imwrite( "../results/point_transformations/inverse_image.jpg", inverse_image );
    imshow("Inverse Image", inverse_image);

    namedWindow("Log Image", WINDOW_AUTOSIZE);
    imwrite( "../results/point_transformations/log_image.jpg", log_image );
    imshow("Log Image", log_image);

    namedWindow("Gamma Corrected Image", WINDOW_AUTOSIZE);
    imwrite( "../results/point_transformations/gamma_corrected_image.jpg", gamma_corrected_image );
    imshow("Gamma Corrected Image", gamma_corrected_image);

    waitKey(0);

    return 0;
}
</code></pre></h3>
								<br></br><br></br>
                            <h2>Histogram Equalization</h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p>Histogram gives the number of occurences of various intensity levels in an image. It can be used to determine the quality of the image. For an image to be visually appealing, the histogram has to be spread apart rather than being concentrated in a narrow range. An image with balanced histogram would be of high contrast, hence more attractive. Images with unbalanced histograms can be equalized in order to increase the contrast. However the side effect of equalization is that a few features might be lost. In this case, the house has disappeared. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Original Image
                             <div style="margin-bottom:25px"></div>
                            <img src="img/week2/histogram_equalization/original_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Original Histogram
                             <div style="margin-bottom:25px"></div>
                            <img src="img/week2/histogram_equalization/original_histogram.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div> 
                            <h4>Equalized Image
                              <div style="margin-bottom:25px"></div>
                            <img src="img/week2/histogram_equalization/equalized_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div> 
                            <h4>Equalized Histogram
                              <div style="margin-bottom:25px"></div>
                            <img src="img/week2/histogram_equalization/equalized_histogram.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
							</div>

                           	<div style="margin-bottom:50px"></div>
                           	 <h3>Code
                            <pre><code class="language-c++">

#include < opencv2/opencv.hpp >
#include < stdio.h >

#define R_WEIGHT 0.2989
#define G_WEIGHT 0.5870
#define B_WEIGHT 0.1140

using namespace cv;

Mat convert_to_grayscale(const Mat& input_image)
{

    Mat rgb_image = input_image.clone();
    Mat grayscale_image = cv::Mat(rgb_image.rows, rgb_image.cols, CV_8UC1, cv::Scalar(0, 0, 0));

    for(int j = 0; j < grayscale_image.rows; j++)
        for(int i = 0; i < grayscale_image.cols; i++)
        {
            Vec3b rgb_value = rgb_image.at<Vec3b>(j, i);
	    grayscale_image.at< uchar >(j,i) = R_WEIGHT*rgb_value[0] + G_WEIGHT*rgb_value[1] + B_WEIGHT*rgb_value[2] ;
        }

    return grayscale_image;

}

void compute_histogram(const Mat& input_image, int histogram[])
{

    for (int i = 0 ; i <256 ; i++)
	histogram[i] = 0;
  
    // Store the frequency of intensities
    for(int j = 0; j < input_image.rows; j++)
        for(int i = 0; i < input_image.cols; i++)
        {
	    histogram[input_image.at< uchar >(j,i)]++;
        }

}

void display_histogram(int histogram[], const char* name)
{
    int hist[256];

    for(int i = 0; i < 256; i++)
    {
        hist[i]=histogram[i];
    }

    // draw the histograms
    int hist_w = 512; int hist_h = 400;
    int bin_w = cvRound((double) hist_w/256);
 
    Mat histogram_image(hist_h, hist_w, CV_8UC1, Scalar(255, 255, 255));
 
    // find the maximum intensity element from histogram
    int max = hist[0];
    for(int i = 1; i < 256; i++){
        if(max < hist[i]){
            max = hist[i];
        }
    }
 
    // normalize the histogram between 0 and histImage.rows
 
    for(int i = 0; i < 256; i++){
        hist[i] = ((double)hist[i]/max)*histogram_image.rows;
    }
 
 
    // draw the intensity line for histogram
    for(int i = 0; i < 256; i++)
    {
        line(histogram_image, Point(bin_w*(i), hist_h),
                              Point(bin_w*(i), hist_h - hist[i]),
             Scalar(0,0,0), 1, 8, 0);
    }
 
    // display histogram
    namedWindow(name, CV_WINDOW_AUTOSIZE);
    imshow(name, histogram_image);

    std::ostringstream display_string ;

    display_string<<"../results/histogram_equalization/"<< name <<".jpg";

    imwrite( display_string.str(), histogram_image );
}

void compute_cumulative_histogram(int histogram[], int cumulative_histogram[])
{
    cumulative_histogram[0] = histogram[0];
  
    for(int j = 1; j < 256 ; j++)
    {
	cumulative_histogram[j] = histogram[j]+cumulative_histogram[j-1];
    }
}

int scale_histogram(int cumulative_histogram[],int scaled_histogram[], float scaling_factor)
{
  
    for(int j = 0; j < 256 ; j++)
    {
	scaled_histogram[j] = cvRound(cumulative_histogram[j]*scaling_factor);
    }

}

Mat equalize_image(const Mat& input_image, int histogram[])
{

   int cumulative_histogram[256], scaled_histogram[256];

   int image_size = input_image.rows*input_image.cols;

   // Compute alpha (scaling factor) based on total number of pixels and maximum intensity   
   float scaling_factor = 255.0/image_size;


   // Compute probability of each intensity by normalizing the histogram
   double intensity_probability[256];
   
   for(int i = 0; i < 256 ; i++)
   {
      intensity_probability[i] =  histogram[i]/image_size;
   }


   // Compute the cumulative histogram by adding all values of lower intensities
   compute_cumulative_histogram(histogram, cumulative_histogram);

   // Scaled the cumulative histogram by the scaling factor
   scale_histogram(cumulative_histogram, scaled_histogram, scaling_factor);

   Mat equalized_image = input_image.clone();

   // Equalize the image by looking at the value from scaled histogram at the intensity 
   // level at the corresponding pixel

   for(int j = 0; j < equalized_image.rows; j++)
       for(int i = 0; i < equalized_image.cols; i++)
       {
	    equalized_image.at< uchar >(j,i) = saturate_cast< uchar >(scaled_histogram[equalized_image.at< uchar >(j,i)]);
       }   

  
   return equalized_image;

}


int main(int argc, char** argv )
{
    Mat rgb_image, grayscale_image, equalized_image;
    rgb_image = imread( "../images/trees.jpg", 1 );

    if ( !rgb_image.data )
    {
        printf("No image data \n");
        return -1;
    }

    int histogram[256], equalized_histogram[256];

    grayscale_image = convert_to_grayscale(rgb_image);

    compute_histogram(grayscale_image, histogram);

    equalized_image = equalize_image(grayscale_image, histogram);
 
    compute_histogram(equalized_image, equalized_histogram);

    namedWindow("Original Image", WINDOW_AUTOSIZE);
    imwrite( "../results/histogram_equalization/original_image.jpg", rgb_image );
    imshow("Original Image", grayscale_image);

    display_histogram(histogram, "original_histogram");

    namedWindow("Equalized Image", WINDOW_AUTOSIZE);
    imwrite( "../results/histogram_equalization/equalized_image.jpg", equalized_image );
    imshow("Equalized Image", equalized_image);

    display_histogram(equalized_histogram, "equalized_histogram");
    
    waitKey(0);

    return 0;
}
</code></pre></h3>
</p>
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
        
        
    </section>
    
        <section id="week3" >
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 3</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week3/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Spatial Image Filters</h2>
                            <div id="25_padding" style="margin-bottom:25px"></div>
                            <p>These filters are basically used for enhancing the images by removing the noise. This process can also be called as smoothing. Spatial filters take into account only the distance between neighbouring pixels and not the value of the pixels. These filters can either be linear (like Mean Filters, Gaussian Filters) or non-linear (like Median Filters). Linear filters/kernels are usually applied to an image using convolution. The results of application of spatial filters, with kernel size of 7 X 7, to noisy images are shown below. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>	
                            <div style="margin-bottom:25px"></div>
							<h4>Original Image <div style="margin-bottom:25px"></div>
                            <img src="img/week3/filter/grayscale_image.jpg" alt=""></h4>                                            
                            <div style="margin-bottom:50px"></div>
                            <h4>Mean Filtered Image
                            <p>An averaging kernel is convolved with the image. Although the noise has reduced, the resulting image is not good enough.
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week3/filter/mean_filtered_image.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Gaussian Filtered Image
                            <p> The gaussian kernel gives more importance to closer pixels than distant ones. When such a filter is convolved with images with salt and pepper noise, the results are not good. 
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week3/filter/gaussian_filtered_image.jpg" alt=""></p></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Median Filtered Image
                            <p>This is a non linear filter, which takes into the account only the median of the neighbouring pixels. As seen below, this filter has almost perfectly restored the noisy image.
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week3/filter/median_filtered_image.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h3>Code
                            <pre><code class="language-c++">
#include < iostream >
#include < opencv2/opencv.hpp >
#include < math.h >
#include < stdlib.h >

#define PI 3.14159
#define R_WEIGHT 0.2989
#define G_WEIGHT 0.5870
#define B_WEIGHT 0.1140

using namespace cv;

void swap(int & a1,int & a2)
{
	a1 = a1 + a2;
	a2 = a1 - a2;
	a1 = a1 - a2;
}

void merge(int A[ ] , int start, int mid, int end) {

   //stores the starting position of both parts in temporary variables.
    int p = start ,q = mid+1;

    int Arr[end-start+1] , k=0;

    for(int i = start ;i <= end ;i++) {
        if(p > mid)      //checks if first part comes to an end or not .
           Arr[ k++ ] = A[ q++] ;

       else if ( q > end)   //checks if second part comes to an end or not
           Arr[ k++ ] = A[ p++ ];

       else if( A[ p ] < A[ q ])     //checks which part has smaller element.
          Arr[ k++ ] = A[ p++ ];

       else
          Arr[ k++ ] = A[ q++];
   }
   for (int p=0 ; p< k ;p ++) {
     /* Now the real array has elements in sorted manner including both 
            parts.*/
       A[ start++ ] = Arr[ p ] ;                          
   }
}

void merge_sort (int A[ ] , int start , int end ) {
    if( start < end ) {
       int mid = (start + end ) / 2 ;           // defines the current array in 2 parts .
       merge_sort (A, start , mid ) ;                 // sort the 1st part of array .
       merge_sort (A,mid+1 , end ) ;              // sort the 2nd part of array.

     // merge the both parts by comparing elements of both the parts.
        merge(A,start , mid , end );   
   }                    
}


Mat convert_to_grayscale(const Mat& input_image)
{

    Mat rgb_image = input_image.clone();
    Mat grayscale_image = cv::Mat(rgb_image.rows, rgb_image.cols, CV_8UC1, cv::Scalar(0, 0, 0));

    for(int j = 0; j < grayscale_image.rows; j++)
        for(int i = 0; i < grayscale_image.cols; i++)
        {
            Vec3b rgb_value = rgb_image.at<Vec3b>(j, i);
	    grayscale_image.at< uchar >(j,i) = R_WEIGHT*rgb_value[0] + G_WEIGHT*rgb_value[1] + B_WEIGHT*rgb_value[2] ;
        }

    return grayscale_image;

}

Mat image_padding(const Mat& input_image, int offset)
{

   Mat padded_image = Mat(input_image.rows+2*offset, input_image.cols+2*offset, CV_8UC1, 0.0);

   for(int j = 0; j < input_image.rows ; j++)
        for(int i = 0; i < input_image.cols; i++)
        {
	    padded_image.at< uchar >(j+offset,i+offset) = input_image.at< uchar >(j,i);
        }

    return padded_image;

}

Mat image_depadding(const Mat& input_image, int offset)
{

   Mat depadded_image = Mat(input_image.rows-2*offset, input_image.cols-2*offset, CV_8UC1, 0.0);

   for(int j = 0; j < input_image.rows-2*offset ; j++)
        for(int i = 0; i < input_image.cols-2*offset; i++)
        {
	    depadded_image.at< uchar >(j,i) = input_image.at< uchar >(j+offset,i+offset);
        }

    return depadded_image;

}

Mat convolve(const Mat& input_image, const Mat& kernel)
{
  
   int kernel_size = kernel.rows;

   int offset;

   if(kernel_size % 2 != 0)
   {
	offset = (kernel_size+1)/2 - 1;
   }
   else
   {
	offset = (kernel_size)/2 - 1;
   }

  Mat padded_image = image_padding(input_image, offset);

  Mat flipped_kernel = Mat(kernel.rows, kernel.cols, CV_32F, 0.0);

   for(int m = 0; m < kernel_size ; m++)
	for(int n = 0; n < kernel_size; n++)
	{
		flipped_kernel.at< float >(m,n) = kernel.at< float >(kernel_size-m-1,kernel_size-n-1);

	}

  Mat convolved_image = Mat(padded_image.rows, padded_image.cols, CV_8UC1, 0.0);
		

  float value = 0.0;
  for(int j = offset; j < padded_image.rows - offset ; j++)
       for(int i = offset; i < padded_image.cols - offset; i++)
       {		   
	   for(int m = 0; m < kernel_size ; m++)
		for(int n = 0; n < kernel_size; n++)
		{
		    value += (padded_image.at< uchar >(j+m-offset,i+n-offset))*flipped_kernel.at< float >(m,n);		    
		}

	    convolved_image.at< uchar >(j,i)  = (int)value;
	    value = 0;	 
       }

  Mat depadded_image = image_depadding(convolved_image, offset);
  
  return depadded_image;
}

Mat gaussian_filter(const Mat& input_image, int kernel_size, float sigma)
{

   Mat kernel = Mat(kernel_size, kernel_size, CV_32F, 0.0);
   int k;

   if(kernel_size % 2 != 0)
   {
	k = (kernel_size-1)/2;
   }
   else
   {
	k = (kernel_size)/2;
   }

   float value = 0.0,value2 = 0.0;

// Create the Gaussian Kernel
   for(int j = 0; j < kernel_size ; j++)
       for(int i = 0; i < kernel_size; i++)
       {
	    kernel.at< float >(j,i) = (float)( 1.0 /( 2.0*PI*pow(sigma,2) ) ) * exp(-1.0* ( pow(i+1-(k+1),2) + pow(j+1-(k+1),2) ) / ( 2.0 * pow(sigma,2) ) ) ;
	    value += kernel.at< float >(j,i);
       }

 // Normalize kernel , so that the sum of all elements in the kernel is 1
   for(int j = 0; j < kernel_size ; j++)
       for(int i = 0; i < kernel_size; i++)
       {
	    kernel.at< float >(j,i) = kernel.at< float >(j,i)/value ;
       }

   Mat filtered_image = convolve(input_image, kernel);

   return filtered_image;
}

Mat mean_filter(const Mat& input_image, int kernel_size)
{

   Mat kernel = Mat(kernel_size, kernel_size, CV_32F, 0.0);

   for(int j = 0; j < kernel_size ; j++)
       for(int i = 0; i < kernel_size; i++)
       {
	    kernel.at< float >(j,i) = ( 1.0 / pow(kernel_size,2)) ;
       }


   Mat filtered_image = convolve(input_image, kernel);  

   return filtered_image;
}


Mat median_filter(const Mat& input_image, int kernel_size)
{
   int offset;

   if(kernel_size % 2 != 0)
   {
	offset = (kernel_size+1)/2 - 1;
   }
   else
   {
	offset = (kernel_size)/2 - 1;
   }

  Mat padded_image = image_padding(input_image, offset);

  Mat filtered_image = Mat(padded_image.rows, padded_image.cols, CV_8UC1, 0.0);

  int size = kernel_size*kernel_size;
  int neighborhood[size];

  int k;

  int mid ;

   if(kernel_size % 2 != 0)
   { 
	mid = (size+1)/2-1;
   }
   else
   {
	mid = (size)/2-1;
   } 		

  float value = 0.0;
  for(int j = offset; j < padded_image.rows - offset ; j++)
       for(int i = offset; i < padded_image.cols - offset; i++)
       {
	   k = 0;	

	   for(int m = 0; m < kernel_size ; m++)
		for(int n = 0; n < kernel_size; n++)
		{	
		    neighborhood[k] = padded_image.at< uchar >(j+m-offset,i+n-offset) ;
		    k++;
		}

	    merge_sort(neighborhood,0,size-1);

            filtered_image.at< uchar >(j,i)  = neighborhood[mid]; 
       }

  Mat depadded_image = image_depadding(filtered_image, offset);
  
  return depadded_image;

}

int main(int argc, char** argv )
{
    Mat image, grayscale_image, gaussian_filtered_image, mean_filtered_image, median_filtered_image;

    image = imread( "../images/balloons.png", 1 );

    if ( !image.data )
    {
        printf("No image data \n");
        return -1;
    }

    grayscale_image = convert_to_grayscale(image);
    gaussian_filtered_image = gaussian_filter(grayscale_image,7,1.4);
    mean_filtered_image = mean_filter(grayscale_image,7);
    median_filtered_image = median_filter(grayscale_image,7);

    namedWindow("Original Image", WINDOW_AUTOSIZE);
    imwrite( "../results/filter/grayscale_image.jpg", grayscale_image );
    imshow("Original Image", grayscale_image);

    namedWindow("Gaussian Filtered Image", WINDOW_AUTOSIZE);
    imwrite( "../results/filter/gaussian_filtered_image.jpg", gaussian_filtered_image );
    imshow("Gaussian Filtered Image", gaussian_filtered_image );

    namedWindow("Mean Filtered Image", WINDOW_AUTOSIZE);
    imwrite( "../results/filter/mean_filtered_image.jpg", mean_filtered_image );
    imshow("Mean Filtered Image", mean_filtered_image);

    namedWindow("Median Filtered Image2", WINDOW_AUTOSIZE);
    imwrite( "../results/filter/median_filtered_image.jpg", median_filtered_image );
    imshow("Median Filtered Image", median_filtered_image);

    waitKey(0);

    return 0;
}
</code></pre></h3>
								<br></br><br></br>
                            <h2>Sharpening</h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p>Sharpening is the process by which the edges of an image are enhanced. It is basically a 3 step process. The first step involves low pass filtering an image using either an averaging or gaussian filter. Then the resultant image is subtracted from the input image, which is equivalent to high pass filtering an image. A proportion of this high pass filtered image , as determined by alpha, is added to the input image. This results in a sharpened image. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Original Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week3/sharpening/grayscale_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Low Pass Filtered Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week3/sharpening/low_pass_filtered_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>High Pass Filtered Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week3/sharpening/high_pass_filtered_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Sharpened Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week3/sharpening/sharpened_image.jpg" alt=""> </h4>
							</div>

                           	<div style="margin-bottom:50px"></div>
                           	 <h3>Code
                            <pre><code class="language-c++">
#include < iostream >
#include < opencv2/opencv.hpp >
#include < math.h >
#include < stdlib.h >

#define PI 3.14159
#define R_WEIGHT 0.2989
#define G_WEIGHT 0.5870
#define B_WEIGHT 0.1140

using namespace cv;

Mat convert_to_grayscale(const Mat& input_image)
{

    Mat rgb_image = input_image.clone();
    Mat grayscale_image = cv::Mat(rgb_image.rows, rgb_image.cols, CV_8UC1, cv::Scalar(0, 0, 0));

    for(int j = 0; j < grayscale_image.rows; j++)
        for(int i = 0; i < grayscale_image.cols; i++)
        {
            Vec3b rgb_value = rgb_image.at<Vec3b>(j, i);
	    grayscale_image.at< uchar >(j,i) = R_WEIGHT*rgb_value[0] + G_WEIGHT*rgb_value[1] + B_WEIGHT*rgb_value[2] ;
        }

    return grayscale_image;

}

Mat sharpen(const Mat& input_image, int kernel_size, float alpha)
{
  Mat low_pass_filtered_image, high_pass_filtered_image, sharpened_image;
  low_pass_filtered_image = input_image.clone();

  //Low pass filter the image using Gaussian
  blur( input_image, low_pass_filtered_image, Size( kernel_size, kernel_size ));

  high_pass_filtered_image = input_image.clone();
  sharpened_image = input_image.clone();  

  for(int j = 0; j < input_image.rows; j++)
	for(int i = 0; i < input_image.cols; i++)
	{

	    //High pass filter the image by subtracting input_image from low pass filtered image and saturate the output
	    high_pass_filtered_image.at< uchar >(j,i) = saturate_cast< uchar >(input_image.at< uchar >(j,i) - low_pass_filtered_image.at< uchar >(j,i));

	    //Sharpen the image by doing weighted addition of the high pass filtered image to the input image and saturate the output
	    sharpened_image.at< uchar >(j,i) =  saturate_cast< uchar >(input_image.at< uchar >(j,i) + alpha*high_pass_filtered_image.at< uchar >(j,i));
		
	}

  namedWindow("HPF Image", WINDOW_AUTOSIZE);
  imwrite( "../results/sharpening/high_pass_filtered_image.jpg", high_pass_filtered_image);
  imshow("HPF Image", high_pass_filtered_image);

  namedWindow("LPF Image", WINDOW_AUTOSIZE);
  imwrite( "../results/sharpening/low_pass_filtered_image.jpg", low_pass_filtered_image);
  imshow("LPF Image", low_pass_filtered_image);
  
  return sharpened_image;

}

int main(int argc, char** argv )
{
    Mat image, grayscale_image, sharpened_image, sharpened_image2, sharpened_image3;

    image = imread( "../images/moon.png", 1 );

    if ( !image.data )
    {
        printf("No image data \n");
        return -1;
    }

    grayscale_image = convert_to_grayscale(image);
    sharpened_image = sharpen(grayscale_image,9,0.5);

    namedWindow("Original Image", WINDOW_AUTOSIZE);
    imwrite( "../results/sharpening/grayscale_image.jpg", grayscale_image );
    imshow("Original Image", grayscale_image);

    namedWindow("Sharpened Image", WINDOW_AUTOSIZE);
    imwrite( "../results/sharpening/sharpened_image.jpg", sharpened_image );
    imshow("Sharpened Image", sharpened_image);

    waitKey(0);

    return 0;
}

</code></pre></h3>
</p>
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
        
        
    </section>
    
    
            <section id="week4" class="bg-light-gray" >
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 4</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week4/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Bilateral Filters</h2>
                            <div id="25_padding" style="margin-bottom:25px"></div>
                            <p>This is a modification of gaussian filter. This filter utilizes both the spatial difference and the pixel difference. Hence this filter would be able to remove noise while enhancing the edges. This filter is non-linear in nature due to additional range weight component that is muliplied with the gaussian/spatial weight. Hence computation cannot be done in the frequency domain. From the results below it can be seen that the Bilateral Filter outperforms Gaussian Filter. The bilateral filter smoothens the entire image except at the edges  </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>	
                            <div style="margin-bottom:25px"></div>
							<h4>Image 1 
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/bilateral_filter/grayscale_image1.jpg" alt=""></h4>                                            
                            <div style="margin-bottom:50px"></div>
                            <h4>Bilaterally Filtered Image                           
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/bilateral_filter/bilaterally_filtered_image1.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Gaussian Filtered Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/bilateral_filter/gaussian_filtered_image1.jpg" alt=""></h4>
                            <div style="margin-bottom:75px"></div>
                            <h4>Image 2
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/bilateral_filter/grayscale_image2.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Bilaterally Filtered Image                           
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/bilateral_filter/bilaterally_filtered_image2.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Gaussian Filtered Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/bilateral_filter/gaussian_filtered_image2.jpg" alt=""></h4>
                            <div style="margin-bottom:75px"></div>
                            <h3>Code
                            <pre><code class="language-c++">
#include < iostream >
#include < opencv2/opencv.hpp >

using namespace cv;

Mat image_padding(const Mat& input_image, int offset)
{

   Mat padded_image = Mat(input_image.rows+2*offset, input_image.cols+2*offset, CV_8UC1, 0.0);

   for(int j = 0; j < input_image.rows ; j++)
        for(int i = 0; i < input_image.cols; i++)
        {
	    padded_image.at< uchar >(j+offset,i+offset) = input_image.at< uchar >(j,i);
        }

    return padded_image;

}

Mat image_depadding(const Mat& input_image, int offset)
{

   Mat depadded_image = Mat(input_image.rows-2*offset, input_image.cols-2*offset, CV_8UC1, 0.0);

   for(int j = 0; j < input_image.rows-2*offset ; j++)
        for(int i = 0; i < input_image.cols-2*offset; i++)
        {
	    depadded_image.at< uchar >(j,i) = input_image.at< uchar >(j+offset,i+offset);
        }

    return depadded_image;

}

Mat bilateral_convolve(const Mat& input_image, const Mat& gaussian_kernel, float sigma_r)
{
  
   int kernel_size = gaussian_kernel.rows;

   int offset;

   if(kernel_size % 2 != 0)
   {
	offset = (kernel_size+1)/2 - 1;
   }
   else
   {
	offset = (kernel_size)/2 - 1;
   }

  Mat padded_image = image_padding(input_image, offset);

  Mat convolved_image = Mat(padded_image.rows, padded_image.cols, CV_8UC1, 0.0);		

  float value, range_weight, weight, cumulative_weight;
  int pixel_intensity, neighboring_pixel_intensity ;

  for(int j = offset; j < padded_image.rows - offset ; j++)
       for(int i = offset; i < padded_image.cols - offset; i++)
       {
	   
           int pixel_intensity = padded_image.at< uchar >(j,i);
 	   cumulative_weight = 0.0;
	   value = 0.0;
	   for(int m = 0; m < kernel_size ; m++)
		for(int n = 0; n < kernel_size; n++)
		{
		    neighboring_pixel_intensity = padded_image.at< uchar >(j+m-offset,i+n-offset);
		    range_weight = (float) exp(-1.0* ( pow(pixel_intensity - neighboring_pixel_intensity,2) ) / ( 2.0 * pow(sigma_r,2) ) );
		    weight = gaussian_kernel.at< float >(m,n) * range_weight ;
		    value += neighboring_pixel_intensity*weight;
		    cumulative_weight += weight ;
		    //std::cout<<flipped_kernel.at<double>(m,n)<<std::endl;
		}

	   // Normalize the value
	   convolved_image.at< uchar >(j,i)  = (int) (value/cumulative_weight);	 
       }

  Mat depadded_image = image_depadding(convolved_image, offset);
  
  return depadded_image;
}

Mat bilateral_filter(const Mat& input_image, int kernel_size, float sigma_g, float sigma_r)
{

   Mat kernel = Mat(kernel_size, kernel_size, CV_32F, 0.0);
   int k;

   if(kernel_size % 2 != 0)
   {
	k = (kernel_size-1)/2;
   }
   else
   {
	k = (kernel_size)/2;
   }

// Create the Gaussian Kernel
   for(int j = 0; j < kernel_size ; j++)
       for(int i = 0; i < kernel_size; i++)
       {
	    kernel.at< float >(j,i) = (float) exp(-1.0* ( pow(i+1-(k+1),2) + pow(j+1-(k+1),2) ) / ( 2.0 * pow(sigma_g,2) ) ) ; // ( 1.0 /( 2.0*PI*pow(sigma_g,2) ) ) *
       }

   Mat filtered_image = bilateral_convolve(input_image, kernel, sigma_r);

   return filtered_image;
}

int main(int argc, char** argv )
{
    Mat image1,image2, grayscale_image1,grayscale_image2, bilaterally_filtered_image1,bilaterally_filtered_image2, gaussian_filtered_image1,gaussian_filtered_image2;

    image1 = imread( "../images/bike.jpg", 1 );
    image2 = imread( "../images/tajmahal.jpg", 1 );

    if ( !image1.data || !image2.data )
    {
        printf("No image data \n");
        return -1;
    }

    cvtColor( image1, grayscale_image1, CV_BGR2GRAY );
    GaussianBlur(grayscale_image1, gaussian_filtered_image1, Size(7,7),0,0);
    bilaterally_filtered_image1 = bilateral_filter(grayscale_image1,7,15,10);

    cvtColor( image2, grayscale_image2, CV_BGR2GRAY );
    GaussianBlur(grayscale_image2, gaussian_filtered_image2, Size(7,7),0,0);
    bilaterally_filtered_image2 = bilateral_filter(grayscale_image2,7,15,10);


    namedWindow("Original Image 1", WINDOW_AUTOSIZE);
    imwrite( "../results/bilateral_filter/grayscale_image1.jpg", grayscale_image1 );
    imshow("Original Image 1", grayscale_image1);

    namedWindow("Bilaterally Filtered Image 1", WINDOW_AUTOSIZE);
    imwrite( "../results/bilateral_filter/bilaterally_filtered_image1.jpg", bilaterally_filtered_image1 );
    imshow("Bilaterally Filtered Image 1", bilaterally_filtered_image1 );

    namedWindow("Gaussian Filtered Image 1", WINDOW_AUTOSIZE);
    imwrite( "../results/bilateral_filter/gaussian_filtered_image1.jpg", gaussian_filtered_image1);
    imshow("Gaussian Filtered Image 1", gaussian_filtered_image1);


    namedWindow("Original Image 2", WINDOW_AUTOSIZE);
    imwrite( "../results/bilateral_filter/grayscale_image2.jpg", grayscale_image2 );
    imshow("Original Image 2", grayscale_image2);

    namedWindow("Bilaterally Filtered Image 2", WINDOW_AUTOSIZE);
    imwrite( "../results/bilateral_filter/bilaterally_filtered_image2.jpg", bilaterally_filtered_image2 );
    imshow("Bilaterally Filtered Image 2", bilaterally_filtered_image2 );

    namedWindow("Gaussian Filtered Image 2", WINDOW_AUTOSIZE);
    imwrite( "../results/bilateral_filter/gaussian_filtered_image2.jpg", gaussian_filtered_image2 );
    imshow("Gaussian Filtered Image 2", gaussian_filtered_image2 );



    waitKey(0);

    return 0;
}

</code></pre></h3>
								<br></br><br></br>
                            <h2>Morphological Filters</h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p>These are non-linear filters, that filter images based on shapes. Dilation computes the maximum value of all the pixels in the neighborhood. Erosion computes the minimum value of all the pixels in the neighborhood. Depending on whether the edges are black or white, both these operations may be used to make the edges thinner or thicker. In the images below, the black edges are made thicker by erosion and are made thinner by dilation. These kind of operations are useful in segmentation. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Image 1
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/morphological_filter/grayscale_image1.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Eroded Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/morphological_filter/eroded_image1.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Dilated Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/morphological_filter/dilated_image1.jpg" alt=""> </h4>
                            <div style="margin-bottom:75px"></div>
                            <h4>Image 2
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/morphological_filter/grayscale_image2.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Eroded Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/morphological_filter/eroded_image2.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Dilated Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week4/morphological_filter/dilated_image2.jpg" alt=""> </h4>
							</div>

                           	<div style="margin-bottom:50px"></div>
                           	 <h3>Code
                            <pre><code class="language-c++">
#include < iostream >
#include < opencv2/opencv.hpp >

using namespace cv;

void merge(int A[ ] , int start, int mid, int end) {

   //stores the starting position of both parts in temporary variables.
    int p = start ,q = mid+1;

    int Arr[end-start+1] , k=0;

    for(int i = start ;i <= end ;i++) {
        if(p > mid)      //checks if first part comes to an end or not .
           Arr[ k++ ] = A[ q++] ;

       else if ( q > end)   //checks if second part comes to an end or not
           Arr[ k++ ] = A[ p++ ];

       else if( A[ p ] < A[ q ])     //checks which part has smaller element.
          Arr[ k++ ] = A[ p++ ];

       else
          Arr[ k++ ] = A[ q++];
   }
   for (int p=0 ; p< k ;p ++) {
     /* Now the real array has elements in sorted manner including both 
            parts.*/
       A[ start++ ] = Arr[ p ] ;                          
   }
}

void merge_sort (int A[ ] , int start , int end ) {
    if( start < end ) {
       int mid = (start + end ) / 2 ;           // defines the current array in 2 parts .
       merge_sort (A, start , mid ) ;                 // sort the 1st part of array .
       merge_sort (A,mid+1 , end ) ;              // sort the 2nd part of array.

     // merge the both parts by comparing elements of both the parts.
        merge(A,start , mid , end );   
   }                    
}

Mat image_padding(const Mat& input_image, int offset)
{

   Mat padded_image = Mat(input_image.rows+2*offset, input_image.cols+2*offset, CV_8UC1, 0.0);

   for(int j = 0; j < input_image.rows ; j++)
        for(int i = 0; i < input_image.cols; i++)
        {
	    padded_image.at< uchar >(j+offset,i+offset) = input_image.at< uchar >(j,i);
        }

    return padded_image;

}

Mat image_depadding(const Mat& input_image, int offset)
{

   Mat depadded_image = Mat(input_image.rows-2*offset, input_image.cols-2*offset, CV_8UC1, 0.0);

   for(int j = 0; j < input_image.rows-2*offset ; j++)
        for(int i = 0; i < input_image.cols-2*offset; i++)
        {
	    depadded_image.at< uchar >(j,i) = input_image.at< uchar >(j+offset,i+offset);
        }

    return depadded_image;

}

Mat morphological_filter(const Mat& input_image, int kernel_size,std::string type )
{
   int offset;

   if(kernel_size % 2 != 0)
   {
	offset = (kernel_size+1)/2 - 1;
   }
   else
   {
	offset = (kernel_size)/2 - 1;
   }

  Mat padded_image = image_padding(input_image, offset);

  Mat filtered_image = Mat(padded_image.rows, padded_image.cols, CV_8UC1, 0.0);

  int size = kernel_size*kernel_size;
  int neighborhood[size];

  int k;
		

  float value = 0.0;
  for(int j = offset; j < padded_image.rows - offset ; j++)
       for(int i = offset; i < padded_image.cols - offset; i++)
       {
	   k = 0;	

	   for(int m = 0; m < kernel_size ; m++)
		for(int n = 0; n < kernel_size; n++)
		{
		
		    neighborhood[k] = padded_image.at< uchar >(j+m-offset,i+n-offset) ;
		    k++;
		}

	    merge_sort(neighborhood,0,size-1);

	   if(type == "erosion")
		filtered_image.at< uchar >(j,i)  = neighborhood[0]; 
	   
	   else if(type == "dilation")
		filtered_image.at< uchar >(j,i)  = neighborhood[k-1]; 
       }

  Mat depadded_image = image_depadding(filtered_image, offset);
  
  return depadded_image;

}

int main(int argc, char** argv )
{
    Mat image1, grayscale_image1, eroded_image1, dilated_image1,image2, grayscale_image2, eroded_image2, dilated_image2;

    image1 = imread( "../images/letter_a.jpg", 1 );
    image2 = imread( "../images/fingerprint.png", 1 );

    if ( !image1.data || !image2.data )
    {
        printf("No image data \n");
        return -1;
    }

    cvtColor( image1, grayscale_image1, CV_BGR2GRAY );
    eroded_image1 = morphological_filter(grayscale_image1,3,"erosion");
    dilated_image1 = morphological_filter(grayscale_image1,3,"dilation");

    cvtColor( image2, grayscale_image2, CV_BGR2GRAY );
    eroded_image2 = morphological_filter(grayscale_image2,3,"erosion");
    dilated_image2 = morphological_filter(grayscale_image2,3,"dilation");

    namedWindow("Original Image 1", WINDOW_AUTOSIZE);
    imwrite( "../results/morphological_filter/grayscale_image1.jpg", grayscale_image1 );
    imshow("Original Image 1", grayscale_image1);

    namedWindow("Eroded Image 1", WINDOW_AUTOSIZE);
    imwrite( "../results/morphological_filter/eroded_image1.jpg", eroded_image1 );
    imshow("Eroded Image 1", eroded_image1 );

    namedWindow("Dilated Image 1", WINDOW_AUTOSIZE);
    imwrite( "../results/morphological_filter/dilated_image1.jpg", dilated_image1 );
    imshow("Dilated Image 1", dilated_image1);

    namedWindow("Original Image 2", WINDOW_AUTOSIZE);
    imwrite( "../results/morphological_filter/grayscale_image2.jpg", grayscale_image2 );
    imshow("Original Image 2", grayscale_image2);

    namedWindow("Eroded Image 2", WINDOW_AUTOSIZE);
    imwrite( "../results/morphological_filter/eroded_image2.jpg", eroded_image2 );
    imshow("Eroded Image 2", eroded_image2 );

    namedWindow("Dilated Image 2", WINDOW_AUTOSIZE);
    imwrite( "../results/morphological_filter/dilated_image2.jpg", dilated_image2 );
    imshow("Dilated Image 2", dilated_image2 );

    waitKey(0);

    return 0;
}


</code></pre></h3>
</p>
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
        
        
    </section>
    
    
    
    
    
    
    
    
    
    
    
            <section id="week5" >
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 5</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week5/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Noise Removal </h2>
                            <div id="25_padding" style="margin-bottom:25px"></div>
                            <p>Provided below are some images from which the type of noise in it is analyzed and a suitable filtering technique is chosen and applied to remove the noise.</p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>	
                            <div style="margin-bottom:25px"></div>
							<h4>Image 1 <div style="margin-bottom:25px"></div>
                            <img src="img/week5/images/631Lab1-brightim.jpg" alt=""></h4>                                            
                            <div style="margin-bottom:50px"></div>
                            <h4>Histogram Equalization 
                            <p>The above image is very bright. In order to make the features visible, the contrast has to be enhanced. This can be done by equalizing its histogram so that the distribution of intensities of the image is spread across the spectrum rather than being concentrated at a particular intensity
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/filter/equalized_image_1.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 2
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/images/631Lab1-darkim.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Histogram Equalization
                            <p>The above image is very dark and similiar to the previous example, the contrast has to be enhanced by histogram equalization.
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/filter/equalized_image_2.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Gaussian Filter 
                            <p>The equalized image is a bit noisy and has small/continous perturbations. A gaussian filter can be applied to the above image in order smoothen the image and reduce the noise
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/filter/gaussian_filtered_image_2.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 3
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/images/631Lab1-noisyLena.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Median Filter
                            <p>The noise in the above image can be classified as salt and pepper noise. This kind of noise is characterized by random sprinkle of extreme intensities across the image. In order to remove such noise, a non-linear filter like Median filter is used,
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/filter/median_filtered_image_3.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 4
                            <p> Source : http://cnx.org/resources/4181ddf62e3a2047d36357f16180ce247b094532/plane_noise1.png
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/images/noisy_plane.png" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Median Filter
                            <p>The above image has salt and pepper noise as well. A median filter can remove it easily.
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/filter/median_filtered_image_4.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 5
                            <p> Source : en.wikipedia.org/wiki/File:Phase_correlation.png
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/images/noisy_lion.png" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Median Filter
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week5/filter/median_filtered_image_5.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                         
							<br></br><br></br>
                            <h2>Canny Edge Detection
                            </h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p>This is a multi-step edge detection algorithm that typically uses and optimizes other edge detection operators such as Prewitt, Robert and Sobel. First the input image is smoothened with a gaussian filter. Then an edge detection operator is applied to the image and the intensity gradient and direction is computed. Based on the gradient and its direction non maximum suppression is applied to make the edges thinner. Strong and weak edges from the resulting image are identified by double thresholding it. The weak edges are then tracked to see if its connected to other strong edges, in which case the weak edge will now be considered as strong edge or will be eliminated otherwise. When comparing this method of edge detection to the traditional edge detection operator's like Sobel, it can be seen from the examples below that the Canny edge detector gives out thinner edges and lesser false edges than the Sobel edge detector. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Signal Flow Diagram
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/signal_flow_diagram.jpg" alt=""> </h3>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Image 1 
                            <div style="margin-bottom:10px"></div>
                            <h4>Sobel Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/sobel_edge_detector1.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Canny Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/canny_edge_detector1.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 2 
                            <div style="margin-bottom:10px"></div>
                            <h4>Sobel Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/sobel_edge_detector2.jpg" alt=""> </h4> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Canny Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/canny_edge_detector2.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 3 
                            <div style="margin-bottom:10px"></div>
                            <h4>Sobel Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/sobel_edge_detector3.jpg" alt=""> </h4> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Canny Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/canny_edge_detector3.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 4 
                            <div style="margin-bottom:10px"></div>
                            <h4>Sobel Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/sobel_edge_detector4.jpg" alt=""> </h4> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Canny Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/canny_edge_detector4.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 5 
                            <div style="margin-bottom:10px"></div>
                            <h4>Sobel Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/sobel_edge_detector5.jpg" alt=""> </h4> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Canny Edge Detection
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week5/canny_edge_detection/canny_edge_detector5.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                           	 <h3>Code
                            <pre><code class="language-c++">
#include < iostream >
#include < opencv2/opencv.hpp >
#include < math.h >
#include < string >

#define PI 3.14159
#define THRESHOLD 35

#define INTERPOLATION true

#define STRONG_EDGE 2
#define WEAK_EDGE 1
#define NOT_EDGE 0

#define THRESHOLD_RATIO_H 0.24
#define THRESHOLD_RATIO_L 0.25

using namespace cv;


Mat image_padding(const Mat& input_image, int offset)
{
   Mat padded_image = Mat(input_image.rows+2*offset, input_image.cols+2*offset, CV_32F, 0.0);

   for(int j = 0; j < input_image.rows ; j++)
        for(int i = 0; i < input_image.cols; i++)
        {
	    padded_image.at< float >(j+offset,i+offset) = input_image.at< uchar >(j,i);
        }

    return padded_image;
}

Mat image_depadding(const Mat& input_image, int offset)
{
   Mat depadded_image = Mat(input_image.rows-2*offset, input_image.cols-2*offset, CV_32F, 0.0);

   for(int j = 0; j < input_image.rows-2*offset ; j++)
        for(int i = 0; i < input_image.cols-2*offset; i++)
        {
	    depadded_image.at< float >(j,i) = input_image.at< float >(j+offset,i+offset);
        }

    return depadded_image;
}

Mat convolve(const Mat& input_image, const Mat& kernel)
{
  
   int kernel_size = kernel.rows;

   int offset;

   if(kernel_size % 2 != 0)
   {
	offset = (kernel_size+1)/2 - 1;
   }
   else
   {
	offset = (kernel_size)/2 - 1;
   }

  Mat padded_image = image_padding(input_image, offset);

  Mat flipped_kernel = Mat(kernel.rows, kernel.cols, CV_32F, 0.0);

   for(int m = 0; m < kernel_size ; m++)
	for(int n = 0; n < kernel_size; n++)
	{
		flipped_kernel.at< float >(m,n) = kernel.at< float >(kernel_size-m-1,kernel_size-n-1);
	}

  Mat convolved_image = Mat(padded_image.rows, padded_image.cols, CV_32F, 0.0);	

  float value = 0.0;
  for(int j = offset; j < padded_image.rows - offset ; j++)
       for(int i = offset; i < padded_image.cols - offset; i++)
       {
		  
	   for(int m = 0; m < kernel_size ; m++)
		for(int n = 0; n < kernel_size; n++)
		{

		    value += (padded_image.at< float >(j+m-offset,i+n-offset))*flipped_kernel.at< float >(m,n);

		}

	   convolved_image.at< float >(j,i)  = value;
	   
	   value = 0;	 
       }

  Mat depadded_image = image_depadding(convolved_image, offset);
  
  return depadded_image;
}


Mat get_image_gradient(const Mat& input_image, const Mat& horizontal_image, const Mat& vertical_image)
{

    Mat filtered_image = Mat(input_image.rows, input_image.cols, CV_8UC1, 0.0);

    for(int j = 0; j < input_image.rows ; j++)
       for(int i = 0; i < input_image.cols; i++)
       {
	    filtered_image.at< uchar >(j,i) = (( sqrt( pow(horizontal_image.at< float >(j,i),2) + pow(vertical_image.at< float >(j,i),2)))) ;
       }

   return filtered_image;

}

Mat get_image_gradient_direction(const Mat& input_image, const Mat& horizontal_image, const Mat& vertical_image)
{

   Mat filtered_image = Mat(input_image.rows, input_image.cols, CV_32F, 0.0);

   for(int j = 0; j < input_image.rows ; j++)
       for(int i = 0; i < input_image.cols; i++)
       {
	    filtered_image.at< float >(j,i) =(float)(atan2( vertical_image.at< float >(j,i), horizontal_image.at< float >(j,i))*180/PI);
       }
 
   return filtered_image;

}

void threshold_image(const Mat& input_image, Mat& thresholded_image)
{

   thresholded_image = input_image.clone();
   for(int j = 0; j < input_image.rows; j++)
	for(int i =0; i < input_image.cols; i++)
	{

		if (input_image.at< uchar >(j,i) >= THRESHOLD)
			thresholded_image.at< uchar >(j,i) = 255;

		else
			thresholded_image.at< uchar >(j,i) = 0;
	}

}

Mat non_maximum_suppression(const Mat& image_gradient,const Mat& gradient_direction, const Mat& horizontal_image, const Mat& vertical_image)
{
   Mat nms_image = image_gradient.clone();

   for(int j = 1; j < image_gradient.rows-1; j++)
	for(int i =1; i < image_gradient.cols-1; i++)
	{
		float angle = gradient_direction.at< float >(j,i);
		
		float top_elements[2];
		float bottom_elements[2];
		float ratio;

		float current_gradient = image_gradient.at< uchar >(j,i) ;

		float bottom_interpolation,top_interpolation;
		
		if(INTERPOLATION)
		{

			if( (angle >= 0 && angle <= 45) || (angle < -135 && angle >= -180))
				{
				  bottom_elements[0] = image_gradient.at< uchar >(j,i+1);
				  bottom_elements[1] = image_gradient.at< uchar >(j+1,i+1);

				  top_elements[0] = image_gradient.at< uchar >(j,i-1);
				  top_elements[1] = image_gradient.at< uchar >(j-1,i-1);
			
				  ratio = abs(vertical_image.at< float >(j,i)/current_gradient);

				  bottom_interpolation = (bottom_elements[1] - bottom_elements[0])*ratio +bottom_elements[0];
				  top_interpolation = (top_elements[1] - top_elements[0])*ratio +top_elements[0];			


				if(current_gradient < bottom_interpolation ||
				   current_gradient < top_interpolation )

					{nms_image.at< uchar >(j,i) = 0;}
				}

			else if( (angle > 45 && angle <= 90) || (angle < -90 && angle >= -135))

				{
				  bottom_elements[0] = image_gradient.at< uchar >(j+1,i);
				  bottom_elements[1] = image_gradient.at< uchar >(j+1,i+1);

				  top_elements[0] = image_gradient.at< uchar >(j-1,i);
				  top_elements[1] = image_gradient.at< uchar >(j-1,i-1);

				
				  ratio = abs(horizontal_image.at< float >(j,i)/current_gradient);

				  bottom_interpolation = (bottom_elements[1] - bottom_elements[0])*ratio +bottom_elements[0];
				  top_interpolation = (top_elements[1] - top_elements[0])*ratio +top_elements[0];			


				if(current_gradient < bottom_interpolation ||
				   current_gradient < top_interpolation )

					{nms_image.at< uchar >(j,i) = 0;	}
				}


			else if( (angle > 90 && angle <= 135) || (angle < -45 && angle >= -90))
				{
				  bottom_elements[0] = image_gradient.at< uchar >(j+1,i);
				  bottom_elements[1] = image_gradient.at< uchar >(j+1,i-1);

				  top_elements[0] = image_gradient.at< uchar >(j-1,i);
				  top_elements[1] = image_gradient.at< uchar >(j-1,i+1);

				
				  ratio = abs(horizontal_image.at< float >(j,i)/current_gradient);

				  bottom_interpolation = (bottom_elements[1] - bottom_elements[0])*ratio +bottom_elements[0];
				  top_interpolation = (top_elements[1] - top_elements[0])*ratio +top_elements[0];			


				if(current_gradient < bottom_interpolation ||
				   current_gradient < top_interpolation )

					{nms_image.at< uchar >(j,i) = 0;	}
				}

			else if( (angle > 135 && angle <= 180) || (angle < 0 && angle >= -45))

				{
				  bottom_elements[0] = image_gradient.at< uchar >(j,i-1);
				  bottom_elements[1] = image_gradient.at< uchar >(j+1,i-1);

				  top_elements[0] = image_gradient.at< uchar >(j,i+1);
				  top_elements[1] = image_gradient.at< uchar >(j-1,i+1);

				
				  ratio = abs(horizontal_image.at< float >(j,i)/current_gradient);

				  bottom_interpolation = (bottom_elements[1] - bottom_elements[0])*ratio +bottom_elements[0];
				  top_interpolation = (top_elements[1] - top_elements[0])*ratio +top_elements[0];			


				if(current_gradient < bottom_interpolation ||
				   current_gradient < top_interpolation )

					{nms_image.at< uchar >(j,i) = 0;		}
				}





		}

		else {
		
			if( (angle >= -22.5 && angle <= 22.5) || (angle < -157.5 && angle >= -180))

				if(image_gradient.at< uchar >(j,i) < image_gradient.at< uchar >(j,i+1) ||
				   image_gradient.at< uchar >(j,i) < image_gradient.at< uchar >(j,i-1) )

					{nms_image.at< uchar >(j,i) = 0;		}

			else if( (angle >= 22.5 && angle <= 67.5) || (angle < -112.5 && angle >= -157.5))

				if(image_gradient.at< uchar >(j,i) < image_gradient.at< uchar >(j+1,i+1) ||
				   image_gradient.at< uchar >(j,i) < image_gradient.at< uchar >(j-1,i-1) )

					{nms_image.at< uchar >(j,i) = 0;		}

			else if( (angle >= 67.5 && angle <= 112.5) || (angle < -67.5 && angle >= -112.5))

				if(image_gradient.at< uchar >(j,i) < image_gradient.at< uchar >(j+1,i) ||
				   image_gradient.at< uchar >(j,i) < image_gradient.at< uchar >(j-1,i) )

					{nms_image.at< uchar >(j,i) = 0;		}

			else if( (angle >= 112.5 && angle <= 157.5) || (angle < -22.5 && angle >= -67.5))

				if(image_gradient.at< uchar >(j,i) < image_gradient.at< uchar >(j+1,i-1) ||
				   image_gradient.at< uchar >(j,i) < image_gradient.at< uchar >(j-1,i+1) )

					{nms_image.at< uchar >(j,i) = 0;		}

			

		}
		
			
	}


   return nms_image;

}

bool check_for_connected_strong_edges(int arr[],int size)
{
    for(int i = 0; i < size; i++)
    {
		if ( arr[i] == STRONG_EDGE )
			return true;	
	}
 
    return false;   

}

Mat hysterisis(const Mat& input_image, int max_threshold, int min_threshold)
{

  Mat double_thresholded_image = input_image.clone() ;
  Mat edge_strength_image = input_image.clone();

  int size = input_image.rows * input_image.cols;	

  float strong_edges_row[size];

  int neighborhood[9];
  int k = 0;

   for(int j = 1; j < input_image.rows-1; j++)
	for(int i =1; i < input_image.cols-1; i++)
	{
		if (input_image.at< uchar >(j,i) >= max_threshold)
			edge_strength_image.at< uchar >(j,i) = STRONG_EDGE;


		else if (input_image.at< uchar >(j,i) > min_threshold && input_image.at< uchar >(j,i) < max_threshold)
			edge_strength_image.at< uchar >(j,i) = WEAK_EDGE ;		


		else
			edge_strength_image.at< uchar >(j,i) = NOT_EDGE;

	}

   for(int j = 1; j < input_image.rows-1; j++)
	for(int i =1; i < input_image.cols-1; i++)
	{
		if (edge_strength_image.at< uchar >(j,i) == WEAK_EDGE)
		    {
			k = 0;
			
			for(int m = -1; m < 2 ; m++)
			    for(int n = -1; n < 2; n++)
			    {		
				neighborhood[k] = edge_strength_image.at< uchar >(j+m,i+n) ;
				k++;
			    }

			if( check_for_connected_strong_edges( neighborhood, 9) )
			{
				double_thresholded_image.at< uchar >(j,i) = 255 ;
				edge_strength_image.at< uchar >(j,i) = STRONG_EDGE;
			}
			else
			{
				double_thresholded_image.at< uchar >(j,i) = 0 ;
				edge_strength_image.at< uchar >(j,i) = WEAK_EDGE;
			}
		    }

		else if (edge_strength_image.at< uchar >(j,i) == STRONG_EDGE)
			double_thresholded_image.at< uchar >(j,i) = 255 ; 

		else
			double_thresholded_image.at< uchar >(j,i) = 0 ;
	}
	
   return double_thresholded_image;


}

void sobel_filter(const Mat& input_image, Mat& image_gradient, Mat& image_gradient_direction, Mat& horizontal_image, Mat& vertical_image)
{

   Mat horizontal_kernel = Mat(3, 3, CV_32F, 0.0);
   Mat vertical_kernel = Mat(3, 3, CV_32F, 0.0);
   Mat nms_image, double_thresholded_image;

   horizontal_kernel.at< float >(0,0) = 1 ;
   horizontal_kernel.at< float >(0,1) = 0 ;
   horizontal_kernel.at< float >(0,2) = -1 ;

   horizontal_kernel.at< float >(1,0) = 2 ;
   horizontal_kernel.at< float >(1,1) = 0 ;
   horizontal_kernel.at< float >(1,2) = -2 ;

   horizontal_kernel.at< float >(2,0) = 1 ;
   horizontal_kernel.at< float >(2,1) = 0 ;
   horizontal_kernel.at< float >(2,2) = -1 ;

   vertical_kernel.at< float >(0,0) = 1 ;
   vertical_kernel.at< float >(0,1) = 2 ;
   vertical_kernel.at< float >(0,2) = 1 ;

   vertical_kernel.at< float >(1,0) = 0 ;
   vertical_kernel.at< float >(1,1) = 0 ;
   vertical_kernel.at< float >(1,2) = 0 ;

   vertical_kernel.at< float >(2,0) = -1 ;
   vertical_kernel.at< float >(2,1) = -2 ;
   vertical_kernel.at< float >(2,2) = -1 ;

   horizontal_image = convolve(input_image, horizontal_kernel); 
   vertical_image = convolve(input_image, vertical_kernel); 

   image_gradient = get_image_gradient(input_image,horizontal_image, vertical_image);

   image_gradient_direction = get_image_gradient_direction(input_image, horizontal_image, vertical_image);

}



void canny_edge_detection(const Mat& input_image, int num)
{
   Mat gaussian_filtered_image, image_gradient,nms_image, double_thresholded_image;
   Mat gradient_direction, horizontal_image, vertical_image, sobel_filtered_image;
 
   gaussian_filtered_image = input_image.clone();

   GaussianBlur(gaussian_filtered_image,gaussian_filtered_image,Size(7,7), 1.4, 1.4, BORDER_DEFAULT);

   sobel_filter(gaussian_filtered_image, image_gradient,gradient_direction, horizontal_image, vertical_image);

   threshold_image(image_gradient,sobel_filtered_image);

   nms_image = non_maximum_suppression(image_gradient,gradient_direction, horizontal_image, vertical_image) ;

   double min, max;

   cv::minMaxLoc(nms_image, &min, &max);

   int max_threshold = max*THRESHOLD_RATIO_H;
   int min_threshold = max_threshold*THRESHOLD_RATIO_L;

   double_thresholded_image = hysterisis( nms_image, max_threshold, min_threshold);


   std::ostringstream path1, path2 ;
   path1 << "../results/canny_edge_detection/sobel_edge_detector" << num << ".jpg" ;
   path2 << "../results/canny_edge_detection/canny_edge_detector" << num << ".jpg" ;

   namedWindow("Image Gradient", WINDOW_AUTOSIZE);
   imwrite( path1.str(), image_gradient );
   imshow("Sobel Image Gradient", image_gradient);

   namedWindow("Sobel Filter ", WINDOW_AUTOSIZE);
   imwrite( path1.str(), sobel_filtered_image );
   imshow("Sobel Filter ", sobel_filtered_image);

   namedWindow("Non Maximum Suppression", WINDOW_AUTOSIZE);
   imwrite( "../results/edge_detection/nms_image"+num+".jpg", nms_image );
   imshow("Non Maximum Suppression", nms_image);

   namedWindow("Hysterisis", WINDOW_AUTOSIZE);
   imwrite(path2.str(), double_thresholded_image );
   imshow("Hysterisis", double_thresholded_image);  

}



int main(int argc, char** argv )
{
    Mat grayscale_image1,grayscale_image2,grayscale_image3,grayscale_image4,grayscale_image5;

    Mat image1 = imread( "../results/filter/equalized_image_1.jpg", 1 );
    Mat image2 = imread( "../results/filter/gaussian_filtered_image_2.jpg", 1 );
    Mat image3 = imread( "../results/filter/median_filtered_image_3.jpg", 1 );

    //http://cnx.org/resources/4181ddf62e3a2047d36357f16180ce247b094532/plane_noise1.png
    Mat image4 = imread( "../results/filter/median_filtered_image_4.jpg", 1 );

    //en.wikipedia.org/wiki/File:Phase_correlation.png
    Mat image5 = imread( "../results/filter/gaussian_filtered_image_5.jpg", 1 );

    cv::Mat resized_image2 = cv::Mat(640, 1000, CV_8UC1, cv::Scalar(0, 0, 0)) ;

    resize(image2,resized_image2,resized_image2.size(),0,0);

    imwrite( "../results/canny_edge_detection/equalized_image2.jpg", resized_image2 );

  if ( !image1.data || !resized_image2.data || !image3.data || !image4.data || !image5.data)
    {
        printf("No image data \n");
        return -1;
    }

    cvtColor( image1, grayscale_image1, CV_BGR2GRAY );
    cvtColor( resized_image2, grayscale_image2, CV_BGR2GRAY );
    cvtColor( image3, grayscale_image3, CV_BGR2GRAY );
    cvtColor( image4, grayscale_image4, CV_BGR2GRAY );
    cvtColor( image5, grayscale_image5, CV_BGR2GRAY );

    canny_edge_detection(grayscale_image1,1);
    canny_edge_detection(grayscale_image2,2);
    canny_edge_detection(grayscale_image3,3);
    canny_edge_detection(grayscale_image4,4);
    canny_edge_detection(grayscale_image5,5);

    waitKey(0);

    return 0;
}

</code></pre></h3>
</p>
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
        
        
    </section>
    
    
    <section id="week6" class="bg-light-gray" >
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 6</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week6/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Inverse and Pseudo-Inverse Filters </h2>
                            <div id="25_padding" style="margin-bottom:25px"></div>
                            <p>Inverse filter is an image restoration technique that is used to deconvolve the point spread function of an image (i.e. To deblur an image). The blurred image is first converted to frequency domain using Fourier Transform and then the frequency domain point spread function is inverted and multiplied element wise with the blurred image in the frequency domain. However in the presence of spectral nulls, the values of the deconvolved image can go to infinity.In order to avoid this Pseudo-Inverse filters are used. In pseudo-inverse filters, the inverted point-spread function is applied only if the value is above a certain threshold. These filters however do not work well in the presence of noise. Results of my implementation of these filters are shown below.</p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>	
                            <div style="margin-bottom:25px"></div>
							<h4>Original Image <div style="margin-bottom:25px"></div>
                            <img src="img/week6/wiener_filter/original_image.jpg" alt=""></h4>                                            
                            <div style="margin-bottom:50px"></div>
                            <h4>Gaussian Blurred Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/wiener_filter/gaussian_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                             <h4>Inverse Filtered Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/inverse_filter/inverse_gaussian_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Pseudo Inverse Filtered Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/inverse_filter/pseudo_inverse_gaussian_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Motion Blurred Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/wiener_filter/motion_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Inverse Filtered Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/inverse_filter/inverse_motion_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Pseudo Inverse Filtered Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/inverse_filter/pseudo_inverse_motion_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Noisy Gaussian Blurred Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/wiener_filter/noisy_gaussian_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Pseudo Inverse Filtered Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/inverse_filter/pseudo_inverse_noisy_gaussian_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Noisy Motion Blurred Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/wiener_filter/noisy_motion_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Pseudo Inverse Filtered Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week6/inverse_filter/pseudo_inverse_noisy_gaussian_blurred_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                         
							<br></br><br></br>
                            <h2>Wiener Filters
                            </h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p> Unlike Inverse Filters, Wiener Filters not only remove the blurring effect but also try to smoothen the noise present in the image. In addition to the point spread functions, it makes use of the signal to noise ratio to remove noise from the image. When you compare the images below with the pseudo-inverse filter versions, it can be seen that performance would be better. However it hasn't completely restored the image. It might need some more tweaking of my implementation of these filters. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Wiener Filtered Noisy Gaussian Blurred Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week6/wiener_filter/restored_gaussian_blurred_image.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Wiener Filtered Noisy Motion Blurred Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week6/wiener_filter/restored_motion_blurred_image.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                           	 <h3>Code
                            <pre><code class="language-c++">
                            
#include < iostream >
#include < opencv2/opencv.hpp >
#include < math.h >

using namespace cv;

#define STD_DEV 50

#define KERNEL_SIZE 17

#define SIGMA 3

#define PI 3.14159

#define THRESHOLD 0.2

Mat image_padding(const Mat& input_image)
{
   Mat padded_image ;
   int rows = getOptimalDFTSize(input_image.rows);
   int cols = getOptimalDFTSize(input_image.cols);
   copyMakeBorder(input_image, padded_image, 0, rows - input_image.rows, 0, cols - input_image.cols, BORDER_CONSTANT, Scalar::all(0));
   return padded_image;

}

Mat add_noise(const Mat& input_image, int std_dev)
{
	Mat noisy_image(input_image.rows,input_image.cols,CV_8U);
	Mat noise(input_image.rows,input_image.cols,CV_32F);
        randn(noise,Scalar::all(0),Scalar::all(STD_DEV));
	noise.convertTo(noisy_image,CV_8U);
	noisy_image += input_image.clone();
	return noisy_image;
}


Mat pad_kernel(cv::Size size,const Mat& kernel, int kernel_size)
{
 
  Mat padded_kernel = Mat::zeros(size, CV_32F);

   for(int j = 0; j < kernel_size ; j++)
       for(int i = 0; i < kernel_size; i++)
       {
	
		padded_kernel.at< float >(j,i) = kernel.at< float >(j,i);

	}

   return padded_kernel;

}

Mat get_gaussian_blur_kernel(int kernel_size, float sigma)
{

   Mat kernel = Mat(kernel_size, kernel_size, CV_32F, 0.0);
   int k;

   if(kernel_size % 2 != 0)
   {
	k = (kernel_size-1)/2;
   }
   else
   {
	k = (kernel_size)/2;
   }

   float value = 0.0;

// Create the Gaussian Kernel
   for(int j = 0; j < kernel_size ; j++)
       for(int i = 0; i < kernel_size; i++)
       {
	    kernel.at< float >(j,i) = (float)( 1.0 /( 2.0*PI*pow(sigma,2) ) ) * exp(-1.0* ( pow(i+1-(k+1),2) + pow(j+1-(k+1),2) ) / ( 2.0 * pow(sigma,2) ) ) ;
	    value += kernel.at< float >(j,i);
       }

 // Normalize kernel , so that the sum of all elements in the kernel is 1
   for(int j = 0; j < kernel_size ; j++)
       for(int i = 0; i < kernel_size; i++)
       {
	    kernel.at< float >(j,i) = kernel.at< float >(j,i)/value ;
       }

   return kernel;
}

Mat get_motion_blur_kernel(int kernel_size)
{
       Mat kernel = Mat::zeros(kernel_size, kernel_size, CV_32F);

       int j = kernel_size/2;

       for(int i = 0; i < kernel_size; i++)
       {
	    kernel.at< float >(j,i) = 1.0/kernel_size ;
       }

       return kernel;
}

Mat fourier_transform(const Mat& padded_image)
{
	Mat image;
	padded_image.convertTo(image,CV_32F);
	//Real part and imaginary part
	Mat images[] = {Mat_< float >(image), Mat::zeros(image.size(), CV_32F)};
	Mat complex_image;
	merge(images, 2, complex_image);         
	dft(complex_image,complex_image);
	return complex_image;

}


Mat power_spectrum(const Mat& input_image)
{
	Mat complex_image = fourier_transform(input_image);
	Mat images[2],image_magnitude,spectrum_image;
	split(complex_image, images);
	magnitude(images[0],images[1],image_magnitude);
	multiply(image_magnitude,image_magnitude,spectrum_image);
	return spectrum_image;
}


Mat wiener_filter(const Mat& noisy_image, const Mat& signal_spectrum, Mat kernel, int kernel_size)
{
   Mat noise(noisy_image.rows,noisy_image.cols,CV_8U);
   randn(noise,Scalar::all(0),Scalar::all(STD_DEV));
  
   Scalar mean_input_image = mean(noisy_image);  

   Mat noise_spectrum = power_spectrum(noise);

   Mat images[2], kernel_images[2];

   Mat complex_image = fourier_transform(noisy_image);

   split(complex_image,images);
 
   Mat padded_kernel = pad_kernel(noisy_image.size(),kernel,kernel_size);

   Mat kernel_spectrum = power_spectrum(padded_kernel);

   Mat kernel_spectrum_squared;

   Mat kernel_complex_image = fourier_transform(padded_kernel);

   split(kernel_complex_image,kernel_images);

   multiply(kernel_spectrum,kernel_spectrum,kernel_spectrum_squared);
   
   Mat inv_snr = noise_spectrum/signal_spectrum;

   Mat weight = Mat::zeros(noisy_image.size(), CV_32F) ; 

   for(int j = 0; j < noisy_image.rows ; j++)
       for(int i = 0; i < noisy_image.cols; i++)
       {
	    if( kernel_spectrum.at< float >(j,i) > THRESHOLD)
	    	weight.at< float >(j,i) = ((kernel_spectrum_squared.at< float >(j,i))/(kernel_spectrum_squared.at< float >(j,i) + inv_snr.at< float >(j,i)))/kernel_spectrum.at< float >(j,i) ;
	
	    else
	    	weight.at< float >(j,i) = 0.0;
       }

   multiply(images[0],weight,images[0]);
   multiply(images[1],weight,images[1]);

   merge(images,2,complex_image);

   idft(complex_image,complex_image);
  
   split(complex_image,images);

   Scalar mean_restored_image = mean(images[0]);

   double scale_factor = mean_input_image.val[0]/mean_restored_image.val[0];

   multiply(images[0],scale_factor,images[0]);

   Mat normalized_image ;

   images[0].convertTo(normalized_image,CV_8UC1);

   return normalized_image;
}


Mat inverse_filter(const Mat& noisy_image, Mat kernel, int kernel_size, bool pseudo_inverse = false)
{
   Mat noise(noisy_image.rows,noisy_image.cols,CV_8U);
   randn(noise,Scalar::all(0),Scalar::all(STD_DEV));
  
   Scalar mean_input_image = mean(noisy_image);  

   Mat images[2], kernel_images[2];

   Mat complex_image = fourier_transform(noisy_image);

   split(complex_image,images);
 
   Mat padded_kernel = pad_kernel(noisy_image.size(),kernel,kernel_size);

   Mat kernel_spectrum = power_spectrum(padded_kernel);

   Mat kernel_spectrum_squared;

   Mat kernel_complex_image = fourier_transform(padded_kernel);

   split(kernel_complex_image,kernel_images);

   multiply(kernel_spectrum,kernel_spectrum,kernel_spectrum_squared);

   Mat weight = Mat::zeros(noisy_image.size(), CV_32F) ; 

   for(int j = 0; j < noisy_image.rows ; j++)
       for(int i = 0; i < noisy_image.cols; i++)
       {
	    if (pseudo_inverse)
	    {
		    if( kernel_spectrum.at< float >(j,i) > THRESHOLD)
		    	weight.at< float >(j,i) = (1/kernel_spectrum.at< float >(j,i)) ;
	
		    else
		    	weight.at< float >(j,i) = 0.0;
	    }

	    else
	    {
		    weight.at< float >(j,i) = (1/kernel_spectrum.at< float >(j,i)) ;

	    }

       }

   multiply(images[0],weight,images[0]);
   multiply(images[1],weight,images[1]);


   merge(images,2,complex_image);

   idft(complex_image,complex_image);
  
   split(complex_image,images);

   Scalar mean_restored_image = mean(images[0]);

   double scale_factor = mean_input_image.val[0]/mean_restored_image.val[0];

   multiply(images[0],scale_factor,images[0]);

   Mat normalized_image ;

   images[0].convertTo(normalized_image,CV_8UC1);

   return normalized_image;
}

int main(int argc, char** argv )
{
    Mat input_image,sample_image,resized_sample_image,padded_image,noisy_gaussian_blurred_image,noisy_motion_blurred_image,gaussian_blurred_image,motion_blurred_image;

    input_image = imread( "../images/horse.jpg", CV_LOAD_IMAGE_GRAYSCALE ) ;

    sample_image = imread( "../images/lena.jpg", CV_LOAD_IMAGE_GRAYSCALE ) ;

    if (!input_image.data)
    {
        printf("No image data \n");
        return -1;
    }

    //GaussianBlur(input_image,input_image,Size(3,3),1.5,1.5);

    padded_image = image_padding(input_image);

    Mat motion_blur_kernel = get_motion_blur_kernel(KERNEL_SIZE);

    Mat gaussian_blur_kernel = get_gaussian_blur_kernel(KERNEL_SIZE, SIGMA);

    filter2D(padded_image,motion_blurred_image,-1,motion_blur_kernel, Point(-1,-1),0,BORDER_DEFAULT);

    filter2D(padded_image,gaussian_blurred_image,-1,gaussian_blur_kernel, Point(-1,-1),0,BORDER_DEFAULT);

    //GaussianBlur(padded_image,gaussian_blurred_image,Size(KERNEL_SIZE,KERNEL_SIZE),SIGMA,SIGMA);

    noisy_gaussian_blurred_image =add_noise(gaussian_blurred_image,STD_DEV);

    noisy_motion_blurred_image =add_noise(motion_blurred_image,STD_DEV);
    
    resize(sample_image, resized_sample_image,padded_image.size());

    Mat sample_image_power_spectrum = power_spectrum(resized_sample_image);

    Mat restored_image2 = wiener_filter(noisy_motion_blurred_image,sample_image_power_spectrum,gaussian_blur_kernel,KERNEL_SIZE);	
    Mat restored_image1 = wiener_filter(noisy_gaussian_blurred_image,sample_image_power_spectrum,motion_blur_kernel,KERNEL_SIZE);

    Mat restored_image3 = inverse_filter(gaussian_blurred_image,gaussian_blur_kernel,KERNEL_SIZE);	
    Mat restored_image4 = inverse_filter(motion_blurred_image,motion_blur_kernel,KERNEL_SIZE);

    Mat restored_image5 = inverse_filter(gaussian_blurred_image,gaussian_blur_kernel,KERNEL_SIZE, true);	
    Mat restored_image6 = inverse_filter(motion_blurred_image,motion_blur_kernel,KERNEL_SIZE, true);

    Mat restored_image7 = inverse_filter(noisy_gaussian_blurred_image,gaussian_blur_kernel,KERNEL_SIZE, true);	
    Mat restored_image8 = inverse_filter(noisy_motion_blurred_image,motion_blur_kernel,KERNEL_SIZE, true);

    namedWindow("Original Image", WINDOW_AUTOSIZE);
    imwrite( "../results/wiener_filter/original_image.jpg", padded_image);
    imshow("Original Image", padded_image);

    namedWindow("Noisy Gaussian Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/wiener_filter/noisy_gaussian_blurred_image.jpg", noisy_gaussian_blurred_image);
    imshow("Noisy Gaussian Blurred Image", noisy_gaussian_blurred_image);

    namedWindow("Noisy Motion Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/wiener_filter/noisy_motion_blurred_image.jpg", noisy_motion_blurred_image);
    imshow("Noisy Motion Blurred Image", noisy_motion_blurred_image);

    namedWindow("Restored Gaussian Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/wiener_filter/restored_gaussian_blurred_image.jpg", restored_image1);
    imshow("Restored Gaussian Blurred Image", restored_image1);

    namedWindow("Restored Motion Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/wiener_filter/restored_motion_blurred_image.jpg", restored_image2);
    imshow("Restored Motion Blurred Image", restored_image2);


    namedWindow("Gaussian Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/inverse_filter/gaussian_blurred_image.jpg", gaussian_blurred_image);
    imshow("Gaussian Blurred Image", gaussian_blurred_image);

    namedWindow("Motion Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/inverse_filter/motion_blurred_image.jpg", motion_blurred_image);
    imshow("Motion Blurred Image", motion_blurred_image);

    namedWindow("Inverse Motion Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/inverse_filter/inverse_motion_blurred_image.jpg", restored_image4);
    imshow("Inverse Motion Blurred Image", restored_image4);

    namedWindow("Inverse Gaussian Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/inverse_filter/inverse_gaussian_blurred_image.jpg", restored_image3);
    imshow("Inverse Gaussian Blurred Image", restored_image3);

    namedWindow("Pseudo Inverse Motion Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/inverse_filter/pseudo_inverse_motion_blurred_image.jpg", restored_image6);
    imshow("Pseudo Inverse Motion Blurred Image", restored_image6);

    namedWindow("Pseudo Inverse Gaussian Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/inverse_filter/pseudo_inverse_gaussian_blurred_image.jpg", restored_image5);
    imshow("Pseudo Inverse Gaussian Blurred Image", restored_image5);

    namedWindow("Pseudo Inverse Noisy Motion Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/inverse_filter/pseudo_inverse_noisy_motion_blurred_image.jpg", restored_image8);
    imshow("Pseudo Inverse Noisy Motion Blurred Image", restored_image8);

    namedWindow("Pseudo Inverse Noisy Gaussian Blurred Image", WINDOW_AUTOSIZE);
    imwrite( "../results/inverse_filter/pseudo_inverse_noisy_gaussian_blurred_image.jpg", restored_image7);
    imshow("Pseudo Inverse Noisy Gaussian Blurred Image", restored_image7);
    waitKey(0);

    return 0;
}

</code></pre></h3>
</p>
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
    </section>
    
    
    
    <section id="week7" >
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 7</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week7/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Run Length Encoding </h2>
                            <div id="25_padding" style="margin-bottom:25px"></div>
                            <p>Run length encoding utilizes the property of image in which usually a number of consecutive pixels are identical. Hence it proves to be a good tool for compressing images. The pixel intensity along with number of consecutive occurances of the same pixel intensity are stored as pairs. The encoding pattern may be from left to right or zig-zag. However, if the image appears to have a huge variance without a lot of consecutive identical intensities, then this encoding technique rather than compressing the image would have expanded the size of the image.  </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results	
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week7/run_length_encoding/run_length_encoding.png" alt=""></h3>                                            
                            <div style="margin-bottom:50px"></div>
                            <h3>Code
                            <pre><code class="language-c++">
                            
#include < iostream >

using namespace std;

int main(int argc, char** argv )
{
  int input_size = 25;
  int a[input_size] = {1,1,1,2,2,3,4,4,4,4,4,4,4,5,5,5,5,3,2,2,2,2,2,2,3};
  //int a[input_size] = {1,1,2,4,2,5,7,1,2,3,4,10,11,15,7,3,3,3,3,6,7,8,1,1};
  int prev_val = 0;
  int count = 0;
  int output_size=0;
  cout << endl << "Input" << endl << endl;
  for(int i = 0 ; i< input_size; i++)
  cout << a[i] << ",";
  cout << endl << endl << "Output" << endl << endl 
  
  for(int i = 0; i< input_size; i++)
  {
	if(prev_val != a[i])
	{
		if(count != 0)
		{
			cout << count << " times - " << prev_val << endl;
			output_size += 2;
		}		
		count = 1;
	}
	else
	{
		++count;
	}

	prev_val = a[i];
  }

  cout << count << " times - " << prev_val << endl;
  output_size += 2;
  

  cout << endl << "Input Size = " << input_size << " , Output Size = " << output_size << endl;
  cout << "Compression Ratio = " << (float)input_size/output_size << " : 1" << endl << endl;

}

							</code></pre></h3>
							</p>
                           
                         
							<br></br><br></br>
                            <h2> Huffman Encoding
                            </h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p> Huffman encoding is a very efficient compression technique that allows variable bit representation based on frequency of intensities across an image. It utilizes the histogram of an image in-order to encode. The most frequent pixel intensity is represented by the smallest number of bits while the least frequent pixel intensity is represented by the largest number of bits. However the huffman code book needs to be stored as an overhead so that the decoder can understand. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week7/huffman_encoding/huffman_encoding.png" alt=""> </h3>
                            <div style="margin-bottom:50px"></div>                           
                           	 <h3>Code
                            <pre><code class="language-c++">
                            
#include < iostream >
#include < bits/stdc++.h >

#define MAX_ELEMENT 10	

using namespace std;

string encoded_data[MAX_ELEMENT+1] = {""};

//Data type used for Priority Queue
class Node
{
   int data;
   unsigned int frequency;


public:

   Node *left, *right;

   Node(int _data, unsigned int _frequency)
   {
      data = _data;
      frequency = _frequency;
   }
   int getData() const { return data; }
   unsigned int getFrequency() const { return frequency; }
};

//Comparator used by Priority Queue for sorting
class FrequencyComparator
{
public:
    int operator() (const Node* p1, const Node* p2)
    {
        return p1->getFrequency() > p2->getFrequency();
    }
};

//Encode bits as a string
void encode(Node* root, string str)
{
    if(root == NULL)
	return;
    if(root->getData() > -1)
	encoded_data[root->getData()] = str;

    encode(root->left, str+"0");
    encode(root->right,str+"1");

}

//Implement Huffman Encoding
void huffman_encode(int frequency_table[], int size)
{

  Node *left_node, *right_node, *top_node;

   // Creates a Min heap of nodes (order by Frequency)
  priority_queue<Node*, vector<Node*>, FrequencyComparator > MinHeap;

  for (int i = 0; i < size; i++)
  {
	if(frequency_table[i] > 0)
		MinHeap.push(new Node(i,frequency_table[i]) );
  }

  while(MinHeap.size() > 1)
  {
	left_node = MinHeap.top();
	MinHeap.pop();

	right_node = MinHeap.top();
	MinHeap.pop();

	// -1 denotes a special node containing frequencies of left and right nodes
	top_node = new Node(-1, left_node->getFrequency() + right_node->getFrequency());
	top_node->left = left_node;
	top_node->right = right_node;
	MinHeap.push(top_node);
  }

  encode(MinHeap.top(),"");

  for(int i = 0; i < size;i++)
  {
	if(frequency_table[i] > 0)
		cout << " Data = " << i << " , Huffman Code = " << encoded_data[i] << " , Frequency = " << frequency_table[i] << endl;
  }
  
  cout << endl;
}


 
int main ()
{
    int input_size = 25;

    int a[input_size] = {1,1,1,1,1,3,4,4,4,4,4,4,4,5,5,5,5,3,7,1,1,1,2,2,9};
  
    int frequency_table[MAX_ELEMENT+1] = {0};

    cout << endl << "Input" << endl << endl;
    
    for(int i = 0 ; i < input_size; i++)
 	cout << a[i] << ",";

    for(int i = 0; i < input_size; i++)
    {
	frequency_table[a[i]] += 1;
    }
  
    cout << endl << endl << "Output - Bit Representation" << endl;

    huffman_encode(frequency_table, MAX_ELEMENT+1);
 
    return 0;
}


                            
</code></pre></h3>
</p>
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
        </section>
        
        
        
        
        
       <section id="week8" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 8</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week8/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Image Deblurring </h2>
                            <div id="25_padding" style="margin-bottom:25px"></div>
                            <p>From the given images flower.tif and flower1.tif , the blurring function was extracted in the frequency domain by dividing the two complex images of the blurred and the original image respectively. Using this blurring function in frequency domain and taking pseudo-inverse of this and multiplying it with the blurred image in frequency domain will restore it and then inverse dft can be performed to view it the spatial domain. However there might be a few artifacts due to loss in certain information. Based on the threshold level, the details in the restored image can vary. Alternatively, the blurred image was sharpened using unsharp mask technique. It looks slightly better than the inverse filter. With regards to the image caterpillar.jpg, I tried to guess the impulse function and tried various kernels like gaussian kernel, averaging kernel. However it didn't restore the image. In this case Blind Deconvolution has to be done by using a cost function by which various kernels and original images are guessed and the best ones are extracted. Due to lack of time , I was not able to implement this algorithm. Classical sharpening technique along with a median filter enhanced the image a bit. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>	
                            <div style="margin-bottom:25px"></div>
							<h4>Original Image 1 <div style="margin-bottom:25px"></div>
                            <img src="img/week8/deconvolution/original_flower.jpg" alt=""></h4>                                            
                            <div style="margin-bottom:50px"></div>
                            <h4>Blurred Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week8/deconvolution/blurred_flower.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                             <h4>Pseudo Inverse Filtered Image With Threshold 0.05
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week8/deconvolution/restored_flower_thresh_0.05.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Pseudo Inverse Filtered Image With Threshold 0.15
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week8/deconvolution/restored_flower_thresh_0.15.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4> Sharpened Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week8/deconvolution/sharpened_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4> Image 2
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week8/deconvolution/caterpillar.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Pseudo Inverse Filtered Image 2
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week8/deconvolution/restored_caterpillar_thresh_0.1.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Sharpened and Median Filtered Image
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week8/deconvolution/sharpened_caterpillar.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>                        
							<br></br><br></br>
                            <h2>Discrete Cosine Transforms
                            </h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p>Discrete Cosine Transforms transforms image into frequency domain comprised of cosine waves. Hence the frequency domain image only has a real part. It is very useful for compression due to its energy compaction property. On the given images, DCT was used for compression. Then the initial values of each block was accepted and rest of them were masked. The masked image is then quantized using JPEG's standard quantization table. This quantized image is then encoded using Run Length Coding which is a lossless encoding technique. It was observed that with increase in block size, the compression ratio and the quality of the image increased as indicated by the PSNR. Most of the information is available towards the starting point of each block. As the size of the block increases, the variance reduces and the valuable information is more concentrated towards the starting point.  </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Image 1
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/baboon.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>DCT Basis 8 X 8
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/baboonC_8_8.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                             <h4>DCT Basis 16 X 16
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/baboonC_16_16.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>DCT Basis 32 X 32
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/baboonC_32_32.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Reconstructed Image 8 X 8
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/baboonC_8_8_reconstructed.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                             <h4>Reconstructed Image 16 X 16
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/baboonC_16_16_reconstructed.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4> Reconstructed Image 32 X 32
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/baboonC_32_32_reconstructed.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image 2
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/moon.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>DCT Basis 8 X 8
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/moon_8_8.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                             <h4>DCT Basis 16 X 16
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/moon_16_16.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>DCT Basis 32 X 32
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/moon_32_32.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Reconstructed Image 8 X 8
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/moon_8_8_reconstructed.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                             <h4>Reconstructed Image 16 X 16
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/moon_16_16_reconstructed.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4> Reconstructed Image 32 X 32
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week8/dct/moon_32_32_reconstructed.jpg" alt=""> </h4></h4>
                            <div style="margin-bottom:50px"></div>
                            
                            
                           	 <h3>Code
                            <pre><code class="language-c++">
 clear;
 close all;
 I = imread('moon.tif');
 %I = rgb2gray(I);
 I = im2double(I);
 OriginalImage = I;
 [k,l] = size(I);
 I = imresize(I, [512 512]);
 n = 8
 T = dctmtx(n);
 dct = @(block_struct) T * block_struct.data * T';
 B = blockproc(I,[n n],dct);
 B2 = B;
 c = 10;
 [M,N]=size(B);
  for x = 1:n
    for y = 1:n
                   
        if x < (n+1)/2 && y < (n+1)/2
             mask(x,y) = 1; 
        else
             mask(x,y) = 0; 
        end
    end
 end         

 selection_matrix = repmat(mask,512/n,512/n);
 B2 = B2.*selection_matrix;

 B2 = imresize(B2,[512 512]);
 
% JPEG Standard Quantization Array
Quantz=[16 11 10 16  24  40  51  61
         12 12 14 19  26  58  60  55
         14 13 16 24  40  57  69  56
         14 17 22 29  51  87  80  62
         18 22 37 56  68 109 103  77
         24 35 55 64  81 104 113  92
         49 64 78 87 103 121 120 101
         72 92 95 98 112 100 103 99 ];
     
prev_val = -1;
count = 0;
output_size = 0;


ResizedQuantizer = repmat(uint8(ceil(double(Quantz)./90000)), 512/8 , 512/8);
 
QuantizedImage = round(B2./double(ResizedQuantizer));

 for x = 1:512
    for y = 1:512
       if prev_val ~= QuantizedImage(x,y)
           if count ~= 0
               output_size = output_size + 2;
           end
           count = 1;
       else
           count = count +1;
       end
       prev_val = QuantizedImage(x,y);
    end
 end     
output_size = output_size +2
compression_ratio = (512*512)/output_size
DeQuantizedImage = QuantizedImage.*double(ResizedQuantizer);
 
invdct = @(block_struct) T' * block_struct.data * T;
I2 = blockproc(DeQuantizedImage,[n n],invdct);
ReconstructedImage = imresize(I2,[k l]);
error = OriginalImage - ReconstructedImage;
MSE = sum(sum(error .* error))/(k*l);
PSNR = 20*log10(max(max(max(OriginalImage)))) - 10*log10(MSE);

textstring = ['N : ' num2str(n) ' X ' num2str(n) ' , Compression Ratio : ' num2str(compression_ratio) ': 1 , PSNR :' num2str(PSNR) ];
position =  [1 50];
figure;
imshow(ReconstructedImage);
title(textstring);
figure;
imshow(OriginalImage);

                            
</code></pre></h3>
</p>
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>                
    </section>  
    
       
           <section id="week9" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">WEEK 9</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/experiments/week9/">here</a></h3>
                </div>
            </div>
        </div>
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                         
							
                            <h2>Adaptive Thresholding</h2>
                            
                            <div style="margin-bottom:25px"></div>
                            <p>Adaptive Thresholding is a data dependent thresholding technique, while global thresholding is a data independent thresholding technique. The fundamental principle of Adaptive Thresholding is that the region of interest can be segmented out by using the blurred version of an image minus a constant as the threshold. Different types of filters like Mean filters, Gaussian filter , Median filter can be used to blur the image. The results of various filters with the same constant and window size are seen below. It can be found that the globally thresholded image suffers due to illumination gradient as a result of which some numbers disappear and the adaptively thresholded images gives out a much better result. This would be really useful for text segmentation. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Input Image
                             <div style="margin-bottom:25px"></div>
                            <img src="img/week9/adaptive_threshold/article.png" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Global Thresholded Image
                             <div style="margin-bottom:25px"></div>
                            <img src="img/week9/adaptive_threshold/global_thresholded_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div> 
                            <h4>Adaptively Thresholded Image with Mean Filter
                              <div style="margin-bottom:25px"></div>
                            <img src="img/week9/adaptive_threshold/mean_thresholded_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div> 
                            <h4>Adaptively Thresholded Image with Median Filter
                              <div style="margin-bottom:25px"></div>
                            <img src="img/week9/adaptive_threshold/median_thresholded_image.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Adaptively Thresholded Image with Gaussian Filter
                              <div style="margin-bottom:25px"></div>
                            <img src="img/week9/adaptive_threshold/gaussian_thresholded_image.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div> 
							</div>

                           	<div style="margin-bottom:50px"></div>
                           	 <h3>Code
                            <pre><code class="language-c++">
                            
                            #include <iostream>
#include "opencv2/opencv.hpp"

#define GAUSSIAN_FILTER 0
#define MEAN_FILTER 1
#define MEDIAN_FILTER 2

using namespace cv;
using namespace std;

void threshold_image(const Mat& input_image, Mat& thresholded_image, float threshold, bool inverse=false, bool adaptive=false, int filter_type = GAUSSIAN_FILTER, int size_k = 11)
{
   thresholded_image = input_image.clone();
   int image_type = input_image.type();
   thresholded_image.convertTo(thresholded_image,CV_8UC1);
   Mat blurred_image;

   if(filter_type == MEAN_FILTER)
	blur(thresholded_image, blurred_image, Size(size_k,size_k), Point(-1,-1));

   else if(filter_type == GAUSSIAN_FILTER)
 	GaussianBlur( thresholded_image,blurred_image, Size(size_k,size_k ), 4, 4);

   else if(filter_type == MEDIAN_FILTER)
 	medianBlur( thresholded_image,blurred_image, size_k);

   if(blurred_image.type() != CV_8UC1)
   	blurred_image.convertTo(blurred_image,image_type);

   float c = threshold;

   for(int j = 1; j < input_image.rows-1; j++)
	for(int i =1; i < input_image.cols-1; i++)
	{
		if(image_type == CV_8UC1)
		{
			if(adaptive)
			{
				threshold =(int) saturate_cast< uchar >(blurred_image.at< uchar >(j,i) - c);				
			}

			if (input_image.at< uchar >(j,i) >= threshold)
				if(inverse)
					thresholded_image.at< uchar >(j,i) = 0;
				else
					thresholded_image.at< uchar >(j,i) = 255;
			else
				if(inverse)
					thresholded_image.at< uchar >(j,i) = 255;
				else
					thresholded_image.at< uchar >(j,i) = 0;
		}
		else if(image_type == CV_32F)
		{
			if(adaptive)
			{
				threshold = (blurred_image.at< float >(j,i) - c);
			}

			if (input_image.at< float >(j,i) >= threshold)
				if(inverse)
					thresholded_image.at< uchar >(j,i) = 0;
				else
					thresholded_image.at< uchar >(j,i) = 255;
			else
				if(inverse)
					thresholded_image.at< uchar >(j,i) = 255;
				else
					thresholded_image.at< uchar >(j,i) = 0;

		}


	}

}

int main(int argc, char** argv )
{
    Mat grayscale_image1;

    Mat image1 = imread( "../images/article.png", 1 );

  if ( !image1.data)
    {
        printf("No image data \n");
        return -1;
    }

    cvtColor( image1, grayscale_image1, CV_BGR2GRAY );

    GaussianBlur( grayscale_image1,grayscale_image1, Size( 7, 7), 3, 3);


    Mat mean_thresholded_image, gaussian_thresholded_image, median_thresholded_image, global_thresholded_image;

    int kernel_size = 11;
    int c = 1;

    threshold_image(grayscale_image1, mean_thresholded_image, c, false, true, MEAN_FILTER, kernel_size);
    threshold_image(grayscale_image1, gaussian_thresholded_image, c, false, true, GAUSSIAN_FILTER, kernel_size);
    threshold_image(grayscale_image1, median_thresholded_image, c, false, true, MEDIAN_FILTER, kernel_size);
    threshold_image(grayscale_image1, global_thresholded_image, 125, false, false);

    namedWindow("Input Image 1", WINDOW_AUTOSIZE);
    imshow("Input Image 1", grayscale_image1); 

    namedWindow("Mean Thresholded Image", WINDOW_AUTOSIZE);
    imwrite( "../results/adaptive_threshold/mean_thresholded_image.jpg", mean_thresholded_image);
    imshow("Mean Thresholded Image", mean_thresholded_image); 

    namedWindow("Gaussian Thresholded Image", WINDOW_AUTOSIZE);
    imwrite( "../results/adaptive_threshold/gaussian_thresholded_image.jpg", gaussian_thresholded_image);
    imshow("Gaussian Thresholded Image", gaussian_thresholded_image); 

    namedWindow("Median Thresholded Image", WINDOW_AUTOSIZE);
    imwrite( "../results/adaptive_threshold/median_thresholded_image.jpg", median_thresholded_image);
    imshow("Median Thresholded Image", median_thresholded_image); 

    namedWindow("Global Thresholded Image", WINDOW_AUTOSIZE);
    imwrite( "../results/adaptive_threshold/global_thresholded_image.jpg", global_thresholded_image);
    imshow("Global Thresholded Image", global_thresholded_image); 

    waitKey(0);

    return 0;
}


</code></pre></h3>
</p>
                          	<br></br><br></br>
                          	
                          	   <h2>Harris Corner Detection</h2>
                            <div style="margin-bottom:25px"></div>
                            <p>Harris Corner Detection method estimates the location of corners based on the gradients at each pixel. It fundamentally relies on the property that corners have large gradients in both x and y direction. The algorithm proceeds by computing the x and y gradients of the image using operators like Sobel. Based on these gradients the Harris Matrix is computed as follows  <div style="margin-bottom:10px"></div>
                            <img src="img/week9/harris_equation.jpg" alt=""><div style="margin-bottom:10px"> Then the harris response is obtained by using the equation R = Det(M) - k(Trace(M))^2 where k's best estimate by Harris was found to be 0.04. The response image is adaptively thresholded in order to obtain the corners. There might be a lot of estimated corners very close to each other , these group of corners are replaced by just one corner by doing non-maxima suppression. The results of Harris Corner Detection on a checkerboard and a picture of a house are seen below. </p>
                            <p>
                            <div style="margin-bottom:50px"></div>
                            <h3>Results</h3>
                            <div style="margin-bottom:25px"></div>
                            <h4>Input Image 1
                            <div style="margin-bottom:25px"></div>
                            <img src="img/week9/harris_corner_detection/checkerboard.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Corners of Image 1
-                            <div style="margin-bottom:10px"></div>
                            <img src="img/week9/harris_corner_detection/corners_2.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Input image 2
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week9/harris_corner_detection/house.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Corners of Image 2
                            <div style="margin-bottom:10px"></div>
                            <img src="img/week9/harris_corner_detection/corners_1.jpg" alt=""></h4>
                            <div style="margin-bottom:50px"></div>
                         
                            <h3>Code
                            <div style="margin-bottom:5px"></div>
                            <pre><code class="language-c++">
                            
#include "iostream"
#include "opencv2/opencv.hpp"

#define THRESHOLD 35000000000
#define DISTANCE_THRESHOLD 8

using namespace cv;
using namespace std;

struct IndexT
{
	int col;
	int row;

	float distance(int j, int i)
	{
		return sqrt(pow((row-j),2)+pow((col-i),2));
	}
};


Mat image_padding(const Mat& input_image, int offset)
{
   Mat padded_image = Mat(input_image.rows+2*offset, input_image.cols+2*offset, CV_32F, 0.0);

   for(int j = 0; j < input_image.rows ; j++)
        for(int i = 0; i < input_image.cols; i++)
        {
	    padded_image.at< float >(j+offset,i+offset) = input_image.at< uchar >(j,i);
        }

    return padded_image;
}

Mat image_depadding(const Mat& input_image, int offset)
{
   Mat depadded_image = Mat(input_image.rows-2*offset, input_image.cols-2*offset, CV_32F, 0.0);

   for(int j = 0; j < input_image.rows-2*offset ; j++)
        for(int i = 0; i < input_image.cols-2*offset; i++)
        {
	    depadded_image.at< float >(j,i) = input_image.at< float >(j+offset,i+offset);
        }

    return depadded_image;
}

Mat convolve(const Mat& input_image, const Mat& kernel)
{
  
   int kernel_size = kernel.rows;

   int offset;

   if(kernel_size % 2 != 0)
   {
	offset = (kernel_size+1)/2 - 1;
   }
   else
   {
	offset = (kernel_size)/2 - 1;
   }

  Mat padded_image = image_padding(input_image, offset);

  Mat flipped_kernel = Mat(kernel.rows, kernel.cols, CV_32F, 0.0);

   for(int m = 0; m < kernel_size ; m++)
	for(int n = 0; n < kernel_size; n++)
	{
		flipped_kernel.at< float >(m,n) = kernel.at< float >(kernel_size-m-1,kernel_size-n-1);
	}

  Mat convolved_image = Mat(padded_image.rows, padded_image.cols, CV_32F, 0.0);	

  float value = 0.0;
  for(int j = offset; j < padded_image.rows - offset ; j++)
       for(int i = offset; i < padded_image.cols - offset; i++)
       {
		  
	   for(int m = 0; m < kernel_size ; m++)
		for(int n = 0; n < kernel_size; n++)
		{

		    value += (padded_image.at< float >(j+m-offset,i+n-offset))*flipped_kernel.at< float >(m,n);

		}

	   convolved_image.at< float >(j,i)  = value;
	   
	   value = 0;	 
       }

  Mat depadded_image = image_depadding(convolved_image, offset);
  
  return depadded_image;
}

void adaptive_threshold(const Mat& input_image, Mat& thresholded_image, float c, bool inverse=false)
{
   thresholded_image = input_image.clone();
   int image_type = input_image.type();

   if(image_type != CV_8UC1)
   	thresholded_image.convertTo(thresholded_image,CV_8UC1);

   Mat blurred_image;

   GaussianBlur( thresholded_image,blurred_image, Size( 5, 5 ), 1.4, 1.4);

   if(blurred_image.type() != CV_8UC1)
   	blurred_image.convertTo(blurred_image,image_type);

   float threshold;

   for(int j = 1; j < input_image.rows-1; j++)
	for(int i =1; i < input_image.cols-1; i++)
	{
		if(image_type == CV_8UC1)
		{
			threshold =(int) saturate_cast< uchar >(blurred_image.at< uchar >(j,i) - c);
	
			if (input_image.at< uchar >(j,i) >= threshold)
				if(inverse)
					thresholded_image.at< uchar >(j,i) = 0;
				else
					thresholded_image.at< uchar >(j,i) = 255;
			else
				if(inverse)
					thresholded_image.at< uchar >(j,i) = 255;
				else
					thresholded_image.at< uchar >(j,i) = 0;
		}
		else if(image_type == CV_32F)
		{
			threshold = (blurred_image.at< float >(j,i) - c);

			if (input_image.at< float >(j,i) >= threshold)
				if(inverse)
					thresholded_image.at< uchar >(j,i) = 0;
				else
					thresholded_image.at< uchar >(j,i) = 255;
			else
				if(inverse)
					thresholded_image.at< uchar >(j,i) = 255;
				else
					thresholded_image.at< uchar >(j,i) = 0;

		}


	}

}



Mat harris_corner_detection(const Mat& input_image)
{

   Mat horizontal_kernel = Mat(3, 3, CV_32F, 0.0);
   Mat vertical_kernel = Mat(3, 3, CV_32F, 0.0);
   Mat image_gradient, image_gradient_direction,converted_image, nms_image, double_thresholded_image;

   horizontal_kernel.at< float >(0,0) = 1.0/9.0 ;
   horizontal_kernel.at< float >(0,1) = 0 ;
   horizontal_kernel.at< float >(0,2) = -1.0/9.0 ;

   horizontal_kernel.at< float >(1,0) = 2/9.0 ;
   horizontal_kernel.at< float >(1,1) = 0 ;
   horizontal_kernel.at< float >(1,2) = -2/9.0 ;

   horizontal_kernel.at< float >(2,0) = 1/9.0 ;
   horizontal_kernel.at< float >(2,1) = 0 ;
   horizontal_kernel.at< float >(2,2) = -1/9.0 ;

   vertical_kernel.at< float >(0,0) = 1/9.0 ;
   vertical_kernel.at< float >(0,1) = 2/9.0 ;
   vertical_kernel.at< float >(0,2) = 1/9.0 ;

   vertical_kernel.at< float >(1,0) = 0 ;
   vertical_kernel.at< float >(1,1) = 0 ;
   vertical_kernel.at< float >(1,2) = 0 ;

   vertical_kernel.at< float >(2,0) = -1/9.0 ;
   vertical_kernel.at< float >(2,1) = -2/9.0 ;
   vertical_kernel.at< float >(2,2) = -1/9.0 ;

   Mat horizontal_image = convolve(input_image, horizontal_kernel); 
   Mat vertical_image = convolve(input_image, vertical_kernel); 

   Mat horizontal_image_squared = Mat(horizontal_image.rows, horizontal_image.cols, CV_32F, 0.0);
   Mat vertical_image_squared  = Mat(horizontal_image.rows, horizontal_image.cols, CV_32F, 0.0);
   Mat horizontal_vertical_image = Mat(horizontal_image.rows, horizontal_image.cols, CV_32F, 0.0);

   Mat combined_image = Mat(horizontal_image.rows, horizontal_image.cols, CV_32F, 0.0);

    for(int j = 0; j < horizontal_image.rows ; j++)
       for(int i = 0; i < horizontal_image.cols ; i++)
       {
	   combined_image.at< float >(j,i) = horizontal_image.at< float >(j,i) + vertical_image.at< float >(j,i);
	   horizontal_image_squared.at< float >(j,i) = pow( horizontal_image.at< float >(j,i), 2);
	   vertical_image_squared.at< float >(j,i)  = pow( vertical_image.at< float >(j,i), 2);
	   horizontal_vertical_image .at< float >(j,i)  = horizontal_image.at< float >(j,i)*vertical_image.at< float >(j,i) ;
	   
       }

   GaussianBlur( horizontal_image_squared, horizontal_image_squared, Size(9,9), 1.4, 1.4, BORDER_DEFAULT );
   GaussianBlur( vertical_image_squared, vertical_image_squared, Size(9,9), 1.4, 1.4, BORDER_DEFAULT );
   GaussianBlur( horizontal_vertical_image, horizontal_vertical_image, Size(9,9), 1.4, 1.4, BORDER_DEFAULT );

   Mat harris_response= Mat(horizontal_image.rows, horizontal_image.cols, CV_32F, 0.0);
   Mat corners= Mat::zeros(horizontal_image.rows, horizontal_image.cols, CV_8UC1 );

   float k = 0.04;

   for(int j = 0; j < horizontal_image.rows ; j++)
      for(int i = 0; i < horizontal_image.cols ; i++)
      {
	   //R = Det(H) - k(Trace(H))^2;
   
	   harris_response.at< float >(j,i) = horizontal_image_squared.at< float >(j,i)*vertical_image_squared.at< float >(j,i) -pow(horizontal_vertical_image.at< float >(j,i),2) 
					    - k*(pow(horizontal_image_squared.at< float >(j,i)+vertical_image_squared.at< float >(j,i),2));
		
      }

   Mat corners2 = Mat::zeros(horizontal_image.rows, horizontal_image.cols, CV_8UC1 );
   
   int size = 5;

   int offset = (size+1)/2 - 1;

    normalize(harris_response, harris_response, 1,0,NORM_MINMAX);
    adaptive_threshold(harris_response, corners, -0.3);

   if(corners.type() != CV_8UC1)
   	corners.convertTo(corners,CV_8UC1);

   std::vector<IndexT> corner_indices;

   for(int j = 0; j < horizontal_image.rows ; j++)
      for(int i = 0; i < horizontal_image.cols ; i++)
      {
	   IndexT current_index;
           current_index.row = j;
	   current_index.col = i;

	   if( corners.at< uchar >(j,i)  > 200)
		if(corner_indices.empty())
			corner_indices.push_back(current_index);
		else
		{
			 bool corner_neighbor = false;
			 for (std::vector<IndexT>::iterator it = corner_indices.begin() ; it != corner_indices.end(); ++it)
			 {
				if(it->distance(j,i) < DISTANCE_THRESHOLD)
					corner_neighbor = true;
			 }	

			 if(!corner_neighbor)
				corner_indices.push_back(current_index);			
		}			
      }

    

    for (std::vector<IndexT>::iterator it = corner_indices.begin() ; it != corner_indices.end(); ++it)
    {
	corners2.at< uchar >(it->row,it->col) = 255;
	
    }	


   Mat image_with_corners = input_image.clone();

   int border_offset = 3;

    for( int j = border_offset; j <  corners2.rows-border_offset ; j++ )
     { for( int i = border_offset; i <  corners2.cols-border_offset; i++ )
	  {
	    if( (int)  corners2.at< uchar >(j,i) == 255 )
	      {
	       circle(  image_with_corners, Point( i, j ), 10,  Scalar(127), 2, 8, 0 );
	      }
	  }
     }

   return image_with_corners; 
}


int main(int argc, char** argv )
{
    Mat grayscale_image1, grayscale_image2;

    Mat image1 = imread( "../images/house.jpg", 1 );
    Mat image2 = imread( "../images/checkerboard.jpg", 1 );

    if ( !image1.data || !image2.data )
     {
        printf("No image data \n");
        return -1;
     }

    cvtColor( image1, grayscale_image1, CV_BGR2GRAY );
    cvtColor( image2, grayscale_image2, CV_BGR2GRAY );

    Mat corners1 = harris_corner_detection(grayscale_image1);

    Mat corners2 = harris_corner_detection(grayscale_image2);

    namedWindow("Input Image 1", WINDOW_AUTOSIZE);
    imshow("Input Image 1", image1); 

    namedWindow("Corner 1", WINDOW_AUTOSIZE);
    imwrite( "../results/harris_corner_detection/corners_1.jpg", corners1);
    imshow("Corner 1", corners1); 

    namedWindow("Input Image 2", WINDOW_AUTOSIZE);
    imshow("Input Image 2", image2); 

    namedWindow("Corner 2", WINDOW_AUTOSIZE);
    imwrite( "../results/harris_corner_detection/corners_2.jpg", corners2);
    imshow("Corner 2", corners2); 
	
    waitKey(0);

    return 0;
}


</code></pre></h3>
                           
                           
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
        
        
    </section>   
    
        <section id="project_progress" >
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">PROJECT</h2>
                    <h3 class="section-subheading text-muted">To view the implementation,&nbsp Click <a href="https://github.com/lkumar93/Image-Processing/tree/master/mobile_scanner/">here</a></h3>
                </div>
            </div>

<!--        <div class="container">
            <div class="row">

            </div>-->
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Mobile Document Scanner</h2>
                    <h3 class="section-subheading text-muted">  </h3>
                </div>
                <div class="col-lg-12">
                    <ul class="timeline">
                        <li>
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> I </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Image Enhancement</h4>
                                    <h4 class="subheading">04/12/2017</h4>
                                </div>
                                <div class="timeline-body">
                                   <div align="justify">
                                    <p class="text-muted">Bilateral filter was used to smoothen the input image while not distorting the edges. Then the contrast of the image is improved by equalizing the histogram. </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <li class="timeline-inverted">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> II </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4> Canny Edge Detection </h4>
                                    <h4 class="subheading">04/15/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted"> Edges are extracted from the enhanced image using Canny Edge Detection method. </p>
									</div>
                                </div>
                            </div>
                        </li>
                                                <li>
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> III </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Morphological Operations</h4>
                                    <h4 class="subheading">04/17/2017</h4>
                                </div>
                                <div class="timeline-body">
                                   <div align="justify">
                                    <p class="text-muted">The edges might have some discontinuities and in-order to rectify that erosion and dilation operations are used for opening and closing (filling) the holes / discontinuities in the edges. </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        
                          <li class="timeline-inverted">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> IV </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Contour Detection</h4>
                                    <h4 class="subheading">04/19/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted"> The enhanced image from the previous step contains a lot of contours. The contours from this image are extracted using OpenCV's 'findContour' function. The largest contour with 4 vertices will contain the document that has to be scanned and this contour is made the reference. </p>
									</div>
                                </div>
                            </div>
                        </li>
                        
                         <li>
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> V </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Corner Detection</h4>
                                    <h4 class="subheading">04/22/2017</h4>
                                </div>
                                <div class="timeline-body">
                                   <div align="justify">
                                    <p class="text-muted"> The 4 corners of the reference contour are extracted using Harris's Corner Detection mthod </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        
                        <li class="timeline-inverted">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> VI </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Perspective Transform and Warping</h4>
                                    <h4 class="subheading">04/24/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted">The four corners are ordered in the clockwise manner. The width and height of the contour are approximated based on  the location of these corners and then a reference rectangle is constructed based on this. The perspective transform between the corners of the contour and the corners of the reference rectangle is computed. Then the pixels inside the contour are warped to the reference rectangle using the perspective transform computed previously.</p>
									</div>
                                </div>
                            </div>
                        </li>
                        
                        <li class="timeline-image">
   							<div class="timeline-image">
                                <h4>
                                    <br><font size="+6"> VII </font> 
                                    <br></h4>
                            </div>
                            <div class="timeline-panel">
                                <div class="timeline-heading">
                                    <h4>Adaptive Thresholding</h4>
                                    <h4 class="subheading">04/26/2017</h4>
                                </div>
                                <div class="timeline-body">
                                    <div align="justify">
                                    	<p class="text-muted"> In order to enhance the warped image and make it suitable for printing purposes, the warped image is thresholded adaptively using the Gaussian Minus C method.</p>
									</div>
                                </div>
                            </div>
                        </li>
                        
                        
                        <li>
                            <div class="timeline-inverted">
                                <div class="timeline-image">
                                <h4>Pending
                                    <br> Enhanced
                                    <br>Functionality</h4>
                            </div>
                            </div>

                        </li>
                 
                    </ul>
                </div>
            </div>
        </div>
    </section>
    
    
    
    <section id="project_results" class="bg-light-gray">
        <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <!-- Project Details Go Here -->
                            <div align="justify">
                            <h2>Results</h2>
                            <div style="margin-bottom:25px"></div>
                            <p>The results of the operations done on the scanned image are shown below.</p>
                            <p>
                            <div style="margin-bottom:25px"></div>
                            <h4>Input Image
                            <div style="margin-bottom:25px"></div>
                            <img src="img/project/mobile_scanner/resized_input.jpg" alt=""> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Image Enhancement
                            <p>
                            <div style="margin-bottom:10px"></div>
                            <img src="img/project/mobile_scanner/image_enhancement.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Canny Edge Detection
                            <p> 
                            <div style="margin-bottom:10px"></div>
                            <img src="img/project/mobile_scanner/canny_edge_detection.jpg" alt=""></p></h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Morphological Operations
                            <p>
                            <div style="margin-bottom:10px"></div>
                            <img src="img/project/mobile_scanner/morphological_operation.jpg" alt=""></p> </h4>
                            <div style="margin-bottom:50px"></div>
                            <h4>Contour Detection
                            <p> 
                            <div style="margin-bottom:10px"></div>
                            <img src="img/project/mobile_scanner/contour_detection.jpg" alt=""></h5></h4>
							<div style="margin-bottom:50px"></div>
                             <h4>Corner Detection
                            <p> 
                            <div style="margin-bottom:10px"></div>
                            <img src="img/project/mobile_scanner/corner_detection.jpg" alt=""></h5></h4>
							<div style="margin-bottom:50px"></div>
                            <h4>Warping using Perspective Transform
                            <p> 
                            <div style="margin-bottom:10px"></div>
                            <img src="img/project/mobile_scanner/warped_image.jpg" alt=""></h5></h4>
							<div style="margin-bottom:50px"></div>
                            <h4>Adaptive Thresholding
                            <p> 
                            <div style="margin-bottom:10px"></div>
                            <img src="img/project/mobile_scanner/adaptive_thresholding.jpg" alt=""></h5></h4>
							<div style="margin-bottom:50px"></div>
                            <h3>Code
                            <div style="margin-bottom:5px"></div>
                            <pre><code class="language-c++">
                            
#include "iostream"
#include "opencv2/opencv.hpp"
#include "morphological_filter.h"
#include "canny_edge_detection.h"
#include "harris_corner_detection.h"

#define THRESHOLD_RATIO_H 0.24
#define THRESHOLD_RATIO_L 0.2

using namespace cv;
using namespace std;

//Order the points as Top_Left, Top_Right, Bottom_Right, Bottom_Left
void order_points(std::vector<IndexT> corner_indices, IndexT ordered_points[])
{
    int max_sum = 0;
    int min_sum = 100000;
    int max_diff = -100000;
    int min_diff = 100000;


    for (std::vector<IndexT>::iterator it = corner_indices.begin() ; it != corner_indices.end(); ++it)
    {
	int sum = it->row + it->col;
	int diff = it->row - it->col;

	if(sum > max_sum)
	{
		max_sum = sum ;
		ordered_points[2] = *it;
	}

	else if(sum < min_sum)
	{
		min_sum = sum ;
		ordered_points[0] = *it;
	}

	if(diff < min_diff )
	{
		min_diff = diff ;
		ordered_points[1] = *it;
	}

	else if(diff > max_diff )
	{
		max_diff = diff ;
		ordered_points[3] = *it;
	}

    }

}


Mat perspective_transform(Point2f corner_points[], Point2f reference_points[])
{
	Mat A = Mat::ones( 3, 3, CV_32F );
	Mat B = Mat::ones( 3, 1, CV_32F );

	A.at< float >(0,0) = corner_points[0].x;
	A.at< float >(1,0) = corner_points[0].y;

	A.at< float >(0,1) = corner_points[1].x;
	A.at< float >(1,1) = corner_points[1].y;

	A.at< float >(0,2) = corner_points[2].x;
	A.at< float >(1,2) = corner_points[2].y;

	B.at< float >(0,0) = corner_points[3].x;
	B.at< float >(1,0) = corner_points[3].y;

	Mat C = Mat::ones( 3, 1, CV_32F );
	C = A.inv()*B;

	Mat M = Mat::ones( 3, 3, CV_32F );

	M.at< float >(0,0) = C.at< float >(0,0)*corner_points[0].x;
	M.at< float >(1,0) =  C.at< float >(0,0)*corner_points[0].y;
	M.at< float >(2,0) =  C.at< float >(0,0);

	M.at< float >(0,1) =  C.at< float >(1,0)* corner_points[1].x;
	M.at< float >(1,1) =  C.at< float >(1,0)*corner_points[1].y;
	M.at< float >(2,1) =  C.at< float >(1,0);

	M.at< float >(0,2) =  C.at< float >(2,0)*corner_points[2].x;
	M.at< float >(1,2) =  C.at< float >(2,0)*corner_points[2].y;
	M.at< float >(2,2) =  C.at< float >(2,0);

	Mat D = Mat::ones( 3, 3, CV_32F );
	Mat E = Mat::ones( 3, 1, CV_32F );

	D.at< float >(0,0) = reference_points[0].x;
	D.at< float >(1,0) = reference_points[0].y;

	D.at< float >(0,1) = reference_points[1].x;
	D.at< float >(1,1) = reference_points[1].y;

	D.at< float >(0,2) = reference_points[2].x;
	D.at< float >(1,2) = reference_points[2].y;

	E.at< float >(0,0) = reference_points[3].x;
	E.at< float >(1,0) = reference_points[3].y;

	Mat F = Mat::ones( 3, 1, CV_32F );
	F = D.inv()*E;

	Mat N = Mat::ones( 3, 3	, CV_32F );

	N.at< float >(0,0) = F.at< float >(0,0)*reference_points[0].x;
	N.at< float >(1,0) = F.at< float >(0,0)*reference_points[0].y;
	N.at< float >(2,0) = F.at< float >(0,0);

	N.at< float >(0,1) = F.at< float >(1,0)*reference_points[1].x;
	N.at< float >(1,1) = F.at< float >(1,0)*reference_points[1].y;
	N.at< float >(2,1) = F.at< float >(1,0);

	N.at< float >(0,2) = F.at< float >(2,0)*reference_points[2].x;
	N.at< float >(1,2) = F.at< float >(2,0)*reference_points[2].y;
	N.at< float >(2,2) = F.at< float >(2,0);


	Mat perspective_transform= Mat::ones( 3, 3, CV_32F );
	perspective_transform = N*M.inv();

	return perspective_transform;
}

int main(int argc, char** argv )
{
    Mat rgb_image, grayscale_image, equalized_image,detected_edges;
    rgb_image = imread( "../images/receipt.jpg", 1 );

    if ( !rgb_image.data )
    {
        printf("No image data \n");
        return -1;
    }

   Mat rgb_image_resized = Mat::zeros( 640, 480, CV_8UC3 );

   float row_ratio = 1;//rgb_image.rows/640.0;
   float col_ratio = 1;//rgb_image.cols/480.0;

   resize(rgb_image, rgb_image_resized , rgb_image_resized.size(), 0, 0);
  
   rgb_image = rgb_image_resized;

   cvtColor( rgb_image_resized , grayscale_image, CV_BGR2GRAY );

   bilateralFilter(grayscale_image, equalized_image, 5, 25, 20);

   equalizeHist(equalized_image,equalized_image);

   Mat canny_detected_edges = canny_edge_detection(equalized_image, THRESHOLD_RATIO_L, THRESHOLD_RATIO_H);

   detected_edges =  morphological_filter( canny_detected_edges, 5, true, false);

   detected_edges.convertTo(detected_edges, CV_8UC1);

   detected_edges =  morphological_filter( detected_edges, 3, false, false);

   detected_edges.convertTo(detected_edges, CV_8UC1);

   detected_edges =  morphological_filter( detected_edges, 3, false, false);

   detected_edges.convertTo(detected_edges, CV_8UC1);

   detected_edges =  morphological_filter( detected_edges, 3, true, false);

   detected_edges.convertTo(detected_edges, CV_8UC1);

   vector<vector<Point> > contours;
   vector<Vec4i> hierarchy;
   vector<Point> largest_contour;
   vector<Point> rectangle;

   findContours( detected_edges, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0) );

   int number_of_contours = contours.size();
  
   if (number_of_contours > 0 )
   {
	  float previous_area = 0.0;
	  float current_area = 0.0;
	  int current_number_of_vertices = 0;
	  int largest_contour_id = 0;
	  float largest_contour_length;
	  float largest_contour_area;
	  int largest_contour_center_x;
	  int largest_contour_center_y;
	  int number_of_vertices;          

	  Mat image_of_contours =  Mat::zeros( 640, 480, CV_8UC1 );//rgb_image_resized;//Mat::zeros( detected_edges.size(), CV_8UC3 );;

 	  RNG rng(12345);

	  // Find contour with largest area
	  for( int i = 0; i < number_of_contours ; i++ )
	  { 

			cv::approxPolyDP(cv::Mat(contours[i]), contours[i], cv::arcLength(cv::Mat(contours[i]), true)*0.05, true);
			current_area = contourArea(contours[i]);
			current_number_of_vertices = contours[i].size();

			if ( current_number_of_vertices == 4 && current_area > previous_area )
			{
				largest_contour_area = current_area;
				largest_contour_id = i;
				number_of_vertices = current_number_of_vertices;	
				previous_area = current_area;	
			}

	    }

       Scalar color = Scalar( 255);//, 255, 0 );
       drawContours( image_of_contours , contours, largest_contour_id, color, 2, 8, hierarchy, 0, Point());	

	   Mat detected_corners;

	   CornerT corner_data = harris_corner_detection(image_of_contours);

	   detected_corners = corner_data.corner_image;

	   IndexT ordered_points[4];

	   order_points(corner_data.corner_indices, ordered_points);

	   for(int i = 0 ; i<4 ; i++)
	   {
			ordered_points[i].row = int(ordered_points[i].row*row_ratio);
			ordered_points[i].col = int(ordered_points[i].col*col_ratio);
	   }	

	   int width1 = int(sqrt(pow(ordered_points[3].col - ordered_points[2].col,2) + pow(ordered_points[3].row - ordered_points[2].row,2)));
	   int width2 = int(sqrt(pow(ordered_points[1].col - ordered_points[0].col,2) + pow(ordered_points[1].row - ordered_points[0].row,2)));

	   int width = (width1 > width2) ? width1 : width2;

	   int height1 = int(sqrt(pow(ordered_points[1].col - ordered_points[2].col,2) + pow(ordered_points[1].row - ordered_points[2].row,2)));
	   int height2 = int(sqrt(pow(ordered_points[3].col - ordered_points[0].col,2) + pow(ordered_points[3].row - ordered_points[0].row,2)));

	   int height = (height1 > height2) ? height1 : height2;

	   Point2f input_rectangle[4], output_rectangle[4];

	   input_rectangle[0] = Point2f(ordered_points[0].col, ordered_points[0].row);
	   input_rectangle[1] = Point2f(ordered_points[1].col, ordered_points[1].row);
	   input_rectangle[2] = Point2f(ordered_points[2].col, ordered_points[2].row);
	   input_rectangle[3] = Point2f(ordered_points[3].col, ordered_points[3].row);

	   output_rectangle[0] = Point2f(0,0);
	   output_rectangle[1] = Point2f(width-1,0);
	   output_rectangle[2] = Point2f(width-1,height-1);
	   output_rectangle[3] = Point2f(0,height-1);

       Mat lambda( 2, 4, CV_32FC1 );

       Mat output( height, width, CV_32FC1 );

	   Mat pt =  perspective_transform(input_rectangle, output_rectangle);

	   Mat transformed_point = Mat::ones(3,1,CV_32F);
	   Mat given_point = Mat::ones(3,1,CV_32F); 

	   Mat warped_image = Mat::ones(height,width,CV_8UC1)*255;

	   for( int j = 0; j <  grayscale_image.rows ; j++ )
   	      for( int i = 0; i <  grayscale_image.cols; i++ )
		{
			given_point.at< float >(0,0) = i;
			given_point.at< float >(1,0) = j;

			transformed_point = pt*given_point;

			int x = cvFloor(transformed_point.at< float >(1,0)/transformed_point.at< float >(2,0));
			int y = cvFloor(transformed_point.at< float >(0,0)/transformed_point.at< float >(2,0));

			if(x >= 0 && x < height && y >=0 && y< width)
				warped_image.at< uchar >(x,y) = grayscale_image.at< uchar >(j,i);

		}

	  medianBlur(warped_image,warped_image,3);	   	

	  lambda = getPerspectiveTransform( input_rectangle, output_rectangle );

	  warpPerspective(rgb_image,output,lambda,output.size() );

      cvtColor(output,output, CV_BGR2GRAY);

	  Mat receipt = output;

	  threshold_image(output, receipt, 6, false, true);

	  namedWindow("Input", WINDOW_AUTOSIZE);
	  imwrite( "../results/mobile_scanner/resized_input.jpg", rgb_image_resized );
	  imshow("Input",rgb_image_resized);

	  namedWindow("Image Enhancement", WINDOW_AUTOSIZE);
	  imwrite( "../results/mobile_scanner/image_enhancement.jpg", equalized_image );
	  imshow("Image Enhancement",equalized_image);  

	  namedWindow("Canny Edge Detection", WINDOW_AUTOSIZE);
	  imwrite( "../results/mobile_scanner/canny_edge_detection.jpg", canny_detected_edges );
	  imshow("Canny Edge Detection",canny_detected_edges);  

	  namedWindow("Morphological Operations", WINDOW_AUTOSIZE);
	  imwrite( "../results/mobile_scanner/morphological_operation.jpg", detected_edges );
	  imshow("Morphological Operations",detected_edges);  

	  namedWindow("Contour Detection", WINDOW_AUTOSIZE);
	  imwrite( "../results/mobile_scanner/contour_detection.jpg", image_of_contours );
	  imshow("Contour Detection",image_of_contours);

	  namedWindow("Corner Detection", WINDOW_AUTOSIZE);
	  imwrite( "../results/mobile_scanner/corner_detection.jpg", detected_corners );
	  imshow("Corner Detection",detected_corners);

	  namedWindow("Warp with Perspective Transform", WINDOW_AUTOSIZE);
	  imwrite( "../results/mobile_scanner/warped_image.jpg", output );
	  imshow("Warp with Perspective Transform",output);	  

	  namedWindow("Adaptive Thresholding", WINDOW_AUTOSIZE);
	  imwrite( "../results/mobile_scanner/adaptive_thresholding.jpg", receipt );
	  imshow("Adaptive Thresholding",receipt);
   }
    
    waitKey(0);

    return 0;
}
                 
</code></pre></h3>
								<br></br><br></br>
                            
                            <ul class="list-inline">
                            </ul>
                        </div>
                    </div>
                </div>
        
        
    </section>
    
     <!-- Team Section -->
    <section id="team" class="bg-light-gray">

        <div class="container">
             <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">ABOUT ME</h2>                    
                </div>
            </div>
             </div>
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center" >
                    <div align="justify">
                    
                    <p class="large text-muted" style="margin-top: 30px;margin-bottom: 30px"><font color="#D4C6C6">I am a second year master's degree student in Robotics, at University of Maryland, College Park (UMD) , specializing in Vision based Control of Autonomous Vehicles. I will be graduating in May 2017.  I look forward to work at the intersection of Robotics, Computer Vision and Machine Learning.</font> </p>
					</div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-12">
                    <div class="team-member">
                        <img src="img/team/1.jpg" class="img-responsive img-circle" id="author">	
                        <h4>Lakshman Kumar K N</h4>
                        <p class="text-muted">Roboticist</p>
                        <ul class="list-inline social-buttons">
                            <li><a href="https://www.linkedin.com/in/lakshmankumar1993/"><i class="fa fa-linkedin"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>           
        </div>
    </section>

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <span class="copyright">&copy; Copyright 2017 | Lakshman Kumar</span>
                </div>
            </div>
        </div>
    </footer>

    <!-- Portfolio Modals -->
	
        </div>
    </div>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/agency.js"></script>

</body>

</html>
